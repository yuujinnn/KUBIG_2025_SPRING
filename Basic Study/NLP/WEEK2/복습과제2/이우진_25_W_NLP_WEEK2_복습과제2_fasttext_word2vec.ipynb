{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFGqc9yOuKEi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eba86eb-82cf-44ad-af4c-b7e21984d0fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Mecab-ko-for-Google-Colab' already exists and is not an empty directory.\n",
            "/content/Mecab-ko-for-Google-Colab\n",
            "Installing konlpy.....\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.11/dist-packages (0.6.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from konlpy) (1.5.1)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from konlpy) (5.3.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.11/dist-packages (from konlpy) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from JPype1>=0.7.0->konlpy) (24.2)\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2025-01-22 13:33:15--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.142.25, 104.192.142.26, 104.192.142.24, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.142.25|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNCE6CDEM6&Signature=bCdURtOz40QrE%2FNTBFQ%2FDiBlc7c%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEN7%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJIMEYCIQD8uJUUGcFE7QyzV1S1AuciO3SEfk26U4YVQBp8ztQTzwIhAJxXauunWaBFU0KOi%2FpmIcHV99IBi9CRbHO5AaWu%2FA20KrACCNf%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEQABoMOTg0NTI1MTAxMTQ2Igwxz4RoncJRtaPUs%2BEqhAIuuUEWGQl6Hr72YoDgoGFwYafBDNDkdw2eBXxXFV81KjbSOxfTMs%2FVFPkSANlIu%2BtkDM5m6%2FVN6YljoARuIRZnBEsys1dCdI1PF%2B%2FLphml6tLU8hVmnj7Wy8%2FBZE1TsVwDlRtCq0gOJZ4gGmClXTGEwbw0qUGf3lsiZwpMvk75WZysxbBD5eFhC9IUIHlcEeZLugdVXIiIDGZp76oWw4FicSLBEuULsavMRt5tlrNOipUX9HKtpz4YwP6mfn8Gsz7tOTZKTUzvZb6LSc6tKOpHa3aCQD1H9ThS1kdrfhbuHkAw3MeHFm5zAgUOg03RgjU9tE1YHjQHuEUAnvA%2F9D3O%2BGXCiDDE5cO8BjqcAUnAScy5ZNDgFnopBN%2FHWbxtPDCNarrwXPeq0Cifi0kKbMYfzZy2SOVkPea00Fropl6MxlJ%2FjBDAcLvdpxpf1yO0W5JebTxqGAH4%2FIH808%2FdYu3d1Bk5i1fcTBEH6jESB9fFW3GwYp019r1UuwMR2iM8KIZggQbw%2Bt0HpdT1S6NDbCbEoAKh%2FtUm1%2Fhy7tl%2BA2yQfXpVDeYDuRLncg%3D%3D&Expires=1737554380 [following]\n",
            "--2025-01-22 13:33:15--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNCE6CDEM6&Signature=bCdURtOz40QrE%2FNTBFQ%2FDiBlc7c%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEN7%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJIMEYCIQD8uJUUGcFE7QyzV1S1AuciO3SEfk26U4YVQBp8ztQTzwIhAJxXauunWaBFU0KOi%2FpmIcHV99IBi9CRbHO5AaWu%2FA20KrACCNf%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEQABoMOTg0NTI1MTAxMTQ2Igwxz4RoncJRtaPUs%2BEqhAIuuUEWGQl6Hr72YoDgoGFwYafBDNDkdw2eBXxXFV81KjbSOxfTMs%2FVFPkSANlIu%2BtkDM5m6%2FVN6YljoARuIRZnBEsys1dCdI1PF%2B%2FLphml6tLU8hVmnj7Wy8%2FBZE1TsVwDlRtCq0gOJZ4gGmClXTGEwbw0qUGf3lsiZwpMvk75WZysxbBD5eFhC9IUIHlcEeZLugdVXIiIDGZp76oWw4FicSLBEuULsavMRt5tlrNOipUX9HKtpz4YwP6mfn8Gsz7tOTZKTUzvZb6LSc6tKOpHa3aCQD1H9ThS1kdrfhbuHkAw3MeHFm5zAgUOg03RgjU9tE1YHjQHuEUAnvA%2F9D3O%2BGXCiDDE5cO8BjqcAUnAScy5ZNDgFnopBN%2FHWbxtPDCNarrwXPeq0Cifi0kKbMYfzZy2SOVkPea00Fropl6MxlJ%2FjBDAcLvdpxpf1yO0W5JebTxqGAH4%2FIH808%2FdYu3d1Bk5i1fcTBEH6jESB9fFW3GwYp019r1UuwMR2iM8KIZggQbw%2Bt0HpdT1S6NDbCbEoAKh%2FtUm1%2Fhy7tl%2BA2yQfXpVDeYDuRLncg%3D%3D&Expires=1737554380\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 16.15.216.154, 16.15.192.252, 3.5.28.150, ...\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|16.15.216.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz.2’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  8.57MB/s    in 0.2s    \n",
            "\n",
            "2025-01-22 13:33:16 (8.57 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz.2’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2025-01-22 13:33:41--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.142.24, 104.192.142.26, 104.192.142.25, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.142.24|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNBRV6FTHA&Signature=EnXDuGW3Fyq4PsddH3xka1z58W8%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEN7%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIQCOwcoR5g7l6ou4eqi9dV%2FiV2xRA8YhJKKtiPFZk5LAiwIgFQoSWC3SUvGuL7jCyLqd0F2zU6e8a0bIKAh9yte7prwqsAII1%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgw5ODQ1MjUxMDExNDYiDMTlAG4YPoxWJWdeGyqEAoM42nr8LAwSIXyPyMCF56W2%2Fs%2FFmXNGbyEmfp8qTjaihyRni0YtvwIeBKtJu7T81WgTMEkfZFPQnx4zw7p3jccI5WkTcrO6wcVamjxF9Ikc8oU5AuZzOcnGBMUY9ltXQADIqC8a5xSSprkBIVkndeRDgVVZ5VyZpPSqZ3uEz5zbhgoZ9o90bqw68QPk%2F4Vh%2FdSveBdXJvQR9MKi0UI3vCBT5maROQ0VjqovKow4Ex6f4jAE1aAoppNCTurjQd3XblYHsujLIb54rHjxox3vTR1jyuaaHYL8wQZi0Yt1oHymtoSmkwnbGpEBfZFmF0dpQ168Le8RJdKoaFWlLfXBjYJkU07SMJHmw7wGOp0BRnAydf7Sks5camZ2UyBYav8bOdB1kaYVj%2BqmKCQevheMbGvtrRPfz8WsnRhNeL5g2HuTW9iQp4NWTE%2B5vieHCrJ39qs9n4jf8urfAMJ2zl4crhHYARGJ0A4pNbbDXhZKHBTe4weCWI3IIDGiRbAM%2FEW76ORrLThnjAphMGE2VtQQ5M9RUoLebHuaUk1txrsdiSWmyQ1FcII0iYX7PA%3D%3D&Expires=1737554457 [following]\n",
            "--2025-01-22 13:33:41--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNBRV6FTHA&Signature=EnXDuGW3Fyq4PsddH3xka1z58W8%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEN7%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJHMEUCIQCOwcoR5g7l6ou4eqi9dV%2FiV2xRA8YhJKKtiPFZk5LAiwIgFQoSWC3SUvGuL7jCyLqd0F2zU6e8a0bIKAh9yte7prwqsAII1%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARAAGgw5ODQ1MjUxMDExNDYiDMTlAG4YPoxWJWdeGyqEAoM42nr8LAwSIXyPyMCF56W2%2Fs%2FFmXNGbyEmfp8qTjaihyRni0YtvwIeBKtJu7T81WgTMEkfZFPQnx4zw7p3jccI5WkTcrO6wcVamjxF9Ikc8oU5AuZzOcnGBMUY9ltXQADIqC8a5xSSprkBIVkndeRDgVVZ5VyZpPSqZ3uEz5zbhgoZ9o90bqw68QPk%2F4Vh%2FdSveBdXJvQR9MKi0UI3vCBT5maROQ0VjqovKow4Ex6f4jAE1aAoppNCTurjQd3XblYHsujLIb54rHjxox3vTR1jyuaaHYL8wQZi0Yt1oHymtoSmkwnbGpEBfZFmF0dpQ168Le8RJdKoaFWlLfXBjYJkU07SMJHmw7wGOp0BRnAydf7Sks5camZ2UyBYav8bOdB1kaYVj%2BqmKCQevheMbGvtrRPfz8WsnRhNeL5g2HuTW9iQp4NWTE%2B5vieHCrJ39qs9n4jf8urfAMJ2zl4crhHYARGJ0A4pNbbDXhZKHBTe4weCWI3IIDGiRbAM%2FEW76ORrLThnjAphMGE2VtQQ5M9RUoLebHuaUk1txrsdiSWmyQ1FcII0iYX7PA%3D%3D&Expires=1737554457\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 16.15.184.238, 16.182.74.161, 52.216.59.137, ...\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|16.15.184.238|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz.2’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  81.7MB/s    in 0.6s    \n",
            "\n",
            "2025-01-22 13:33:42 (81.7 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz.2’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "apt-get update\n",
            "apt-get upgrade\n",
            "apt install curl\n",
            "apt install git\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
            "Done\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n",
            "사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n",
            "NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n",
            "블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n"
          ]
        }
      ],
      "source": [
        "# Colab에 Mecab 설치\n",
        "# 형태소 분석기: 주어진 문장에서 의미 있는 최소 단위인 형태소를 추출하고 그들의 품사를 파악하는 도구\n",
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
        "%cd Mecab-ko-for-Google-Colab\n",
        "!bash install_mecab-ko_on_colab190912.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbP19ZYGpU59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4afca498-6bf8-4776-fee5-01cbf67310b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.11/dist-packages (0.6.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from konlpy) (1.5.1)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from konlpy) (5.3.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.11/dist-packages (from konlpy) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from JPype1>=0.7.0->konlpy) (24.2)\n",
            "Requirement already satisfied: mecab-python in /usr/local/lib/python3.11/dist-packages (1.0.0)\n",
            "Requirement already satisfied: mecab-python3 in /usr/local/lib/python3.11/dist-packages (from mecab-python) (1.0.10)\n",
            "mecab-ko is already installed\n",
            "mecab-ko-dic is already installed\n",
            "mecab-python is already installed\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "# 위의 코드가 작동하지 않을 때 대안 코드 1 실행\n",
        "!pip install konlpy\n",
        "!pip install mecab-python\n",
        "!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dB_bh1mUue11"
      },
      "outputs": [],
      "source": [
        "from konlpy.tag import Mecab\n",
        "mecab = Mecab()\n",
        "#NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ev1dx8jzvoIq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2392b6bf-60bf-4e7c-dd8a-7d0273a458c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hgtk\n",
            "  Downloading hgtk-0.2.1-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Downloading hgtk-0.2.1-py2.py3-none-any.whl (12 kB)\n",
            "Installing collected packages: hgtk\n",
            "Successfully installed hgtk-0.2.1\n"
          ]
        }
      ],
      "source": [
        "# 한글 자모 단위 처리 패키지 설치\n",
        "# 한글을 자음과 모음 단위로 분리하거나, 자음과 모음을 합치는 등의 작업을 할 수 있도록 도와주는 파이썬 라이브러리\n",
        "!pip install hgtk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NiWJSRkBwBvz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23248b47-8ab2-4410-b70e-f96a908a6ff0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fastText'...\n",
            "remote: Enumerating objects: 3998, done.\u001b[K\n",
            "remote: Counting objects: 100% (995/995), done.\u001b[K\n",
            "remote: Compressing objects: 100% (171/171), done.\u001b[K\n",
            "remote: Total 3998 (delta 886), reused 824 (delta 824), pack-reused 3003 (from 2)\u001b[K\n",
            "Receiving objects: 100% (3998/3998), 8.30 MiB | 18.76 MiB/s, done.\n",
            "Resolving deltas: 100% (2527/2527), done.\n",
            "/content/Mecab-ko-for-Google-Colab/fastText\n",
            "c++ -pthread -std=c++17 -march=native -O3 -funroll-loops -DNDEBUG -c src/args.cc\n",
            "c++ -pthread -std=c++17 -march=native -O3 -funroll-loops -DNDEBUG -c src/autotune.cc\n",
            "c++ -pthread -std=c++17 -march=native -O3 -funroll-loops -DNDEBUG -c src/matrix.cc\n",
            "c++ -pthread -std=c++17 -march=native -O3 -funroll-loops -DNDEBUG -c src/dictionary.cc\n",
            "c++ -pthread -std=c++17 -march=native -O3 -funroll-loops -DNDEBUG -c src/loss.cc\n",
            "c++ -pthread -std=c++17 -march=native -O3 -funroll-loops -DNDEBUG -c src/productquantizer.cc\n",
            "c++ -pthread -std=c++17 -march=native -O3 -funroll-loops -DNDEBUG -c src/densematrix.cc\n",
            "c++ -pthread -std=c++17 -march=native -O3 -funroll-loops -DNDEBUG -c src/quantmatrix.cc\n",
            "c++ -pthread -std=c++17 -march=native -O3 -funroll-loops -DNDEBUG -c src/vector.cc\n",
            "c++ -pthread -std=c++17 -march=native -O3 -funroll-loops -DNDEBUG -c src/model.cc\n",
            "c++ -pthread -std=c++17 -march=native -O3 -funroll-loops -DNDEBUG -c src/utils.cc\n",
            "c++ -pthread -std=c++17 -march=native -O3 -funroll-loops -DNDEBUG -c src/meter.cc\n",
            "c++ -pthread -std=c++17 -march=native -O3 -funroll-loops -DNDEBUG -c src/fasttext.cc\n",
            "c++ -pthread -std=c++17 -march=native -O3 -funroll-loops -DNDEBUG args.o autotune.o matrix.o dictionary.o loss.o productquantizer.o densematrix.o quantmatrix.o vector.o model.o utils.o meter.o fasttext.o src/main.cc -o fasttext\n",
            "Processing /content/Mecab-ko-for-Google-Colab/fastText\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext==0.9.2)\n",
            "  Using cached pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from fasttext==0.9.2) (75.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fasttext==0.9.2) (1.26.4)\n",
            "Using cached pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp311-cp311-linux_x86_64.whl size=4313392 sha256=7e22271bc1a44ca70057f1719579d28241015249afa4549ab7914747df079bb2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-q32mxz3z/wheels/22/83/a5/1506e7b3fd51df5006c412e3611aacc23b58d042b03c2f52b4\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.13.6\n"
          ]
        }
      ],
      "source": [
        "# fasttext 설치\n",
        "# fastText는 Facebook AI Research에서 개발한 텍스트 처리 및 언어 모델링 라이브러리 -> 단어 임베딩(Word Embeddings)과 텍스트 분류 작업에 강력한 성능을 보임.\n",
        "!git clone https://github.com/facebookresearch/fastText.git\n",
        "%cd fastText\n",
        "!make\n",
        "!pip install ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L68t-IBUqaIN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1a60813-73ae-425c-ecd6-5b40d7808e0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: hgtk in /usr/local/lib/python3.11/dist-packages (0.2.1)\n"
          ]
        }
      ],
      "source": [
        "#hgtk 설치\n",
        "!pip install hgtk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0FmhT3awOEm"
      },
      "source": [
        "## 1. 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFB3ropAwNnp"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import urllib.request\n",
        "from tqdm import tqdm\n",
        "import hgtk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fq8kmo_uwT1C",
        "outputId": "20d7141f-88a1-4b18-d249-711d6827ce98"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('ratings_total.txt', <http.client.HTTPMessage at 0x7e668ca941d0>)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# 네이버 쇼핑 리뷰\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/bab2min/corpus/master/sentiment/naver_shopping.txt\", filename=\"ratings_total.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zB88TfbcwVmx",
        "outputId": "becdcddb-66ab-43dd-ca81-697d119542ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 리뷰 개수 : 200000\n"
          ]
        }
      ],
      "source": [
        "total_data = pd.read_table('ratings_total.txt', names=['ratings', 'reviews'])\n",
        "print('전체 리뷰 개수 :',len(total_data)) # 전체 리뷰 개수 출력"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "IMzrtayFwXfy",
        "outputId": "c25c760a-4860-4523-accc-93d157cdc410"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   ratings                                            reviews\n",
              "0        5                                            배공빠르고 굿\n",
              "1        2                      택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고\n",
              "2        5  아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...\n",
              "3        2  선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...\n",
              "4        5                  민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b19e31c6-deb4-4336-894a-89202a648076\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ratings</th>\n",
              "      <th>reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>배공빠르고 굿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b19e31c6-deb4-4336-894a-89202a648076')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b19e31c6-deb4-4336-894a-89202a648076 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b19e31c6-deb4-4336-894a-89202a648076');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9375e385-0eee-4576-9e97-cd519684af32\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9375e385-0eee-4576-9e97-cd519684af32')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9375e385-0eee-4576-9e97-cd519684af32 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "total_data"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "total_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3k4x7PAAwdd_"
      },
      "source": [
        "## 2. hgtk 튜토리얼\n",
        "\n",
        "\n",
        "\n",
        "word embedding이 단어 단위의 임베딩이었다면, character embedding은 문자 단위의 임베딩입니다. 한국어를 character embedding할 수 있는 것이 바로 자음 모음 분리기 hgtk입니다.\n",
        "\n",
        " 영어는 하나의 알파벳(52자)를 기준으로 character embedding을 하지만, 한국어에서 하나의 음절별로 character embedding을 하면 11172개의 음절이 있기 때문에 계산량이 너무 많습니다. 따라서 그보다 작은 단위인 자음,모음으로 분리하는 것입니다.\n",
        "\n",
        " >참고 repo: https://github.com/bluedisk/hangul-toolkit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFtjwDZ0wcOW",
        "outputId": "1b3eddbd-664e-4b62-e2aa-4339a0d5b49c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "# 한글인지 체크\n",
        "print(hgtk.checker.is_hangul('ㄱ'))\n",
        "print(hgtk.checker.is_hangul('12'))\n",
        "print(hgtk.checker.is_hangul('a'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dslUKt6rxXWb",
        "outputId": "b72e8983-23d1-4afa-cfcb-3a98dab0d216"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('ㄴ', 'ㅏ', 'ㅁ')\n",
            "남\n"
          ]
        }
      ],
      "source": [
        "# 음절을 초성, 중성, 종성으로 분해\n",
        "print(hgtk.letter.decompose('남'))\n",
        "# 초성, 중성, 종성을 하나의 음절로 결합\n",
        "print(hgtk.letter.compose('ㄴ', 'ㅏ', 'ㅁ'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84dNK0oJxofR",
        "outputId": "8b751cb5-e119-4776-9904-0a3667a134c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "에러 발생\n"
          ]
        }
      ],
      "source": [
        "# 결합할 수 없는 상황에서는 에러 발생\n",
        "try:\n",
        "  hgtk.letter.compose('ㄴ', 'ㅁ', 'ㅁ') # 중성이 없는 경우\n",
        "except:\n",
        "  print('에러 발생')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLO0xL3czHaB"
      },
      "source": [
        "## 3. 데이터 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "967R9oSN2Wp3"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dZQlvCIzBT7"
      },
      "outputs": [],
      "source": [
        "# 한글 단어(token)를 자모 단위로 분리하는 함수\n",
        "def word_to_jamo(token):\n",
        "  def to_special_token(jamo): # 경우에 따라 초, 중, 종성이 다 있는 게 아닌 경우도 있다. 이 경우 -를 반환해주는 함수\n",
        "    if not jamo:\n",
        "      return '-'\n",
        "    else:\n",
        "      return jamo\n",
        "\n",
        "  decomposed_token = ''\n",
        "  for char in token:\n",
        "    try:\n",
        "      # char(음절)을 초성, 중성, 종성으로 분리\n",
        "      cho, jung, jong = hgtk.letter.decompose(char)\n",
        "\n",
        "      # 자모가 빈 문자일 경우 특수문자 -로 대체 -> 위에서 정의한 to_special_token 함수 사용\n",
        "      cho = to_special_token(cho)\n",
        "      jung = to_special_token(jung)\n",
        "      jong = to_special_token(jong)\n",
        "      decomposed_token = decomposed_token + cho + jung + jong\n",
        "\n",
        "    # 만약 char(음절)이 한글이 아닐 경우 자모를 나누지 않고 추가\n",
        "    except Exception as exception:\n",
        "      if type(exception).__name__ == 'NotHangulException':\n",
        "        decomposed_token += char\n",
        "\n",
        "  # 단어 토큰의 자모 단위 분리 결과를 추가\n",
        "  return decomposed_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bc8TkvR13eIH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8252e39a-8c05-46b6-bcc3-9314b13f5571"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ㄴㅏㅁㄷㅗㅇㅅㅐㅇ\n",
            "ㅇㅑ-ㄱㅜ-\n"
          ]
        }
      ],
      "source": [
        "print(word_to_jamo('남동생'))\n",
        "print(word_to_jamo('야구')) # 야구의 경우 종성이 없으므로 종성 부분을 -로 반환"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rec1IWDC3yIF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "882d3269-9510-4290-875f-a549962c0f14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['선물', '용', '으로', '빨리', '받', '아서', '전달', '했어야', '하', '는', '상품', '이', '었', '는데', '머그', '컵', '만', '와서', '당황', '했', '습니다', '.']\n"
          ]
        }
      ],
      "source": [
        "# Mecab을 사용하여 주어진 한글 문장을 형태소(morphemes)로 분리\n",
        "print(mecab.morphs('선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다.'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAZkfbwa339B"
      },
      "outputs": [],
      "source": [
        "# mecab으로 형태소를 분리해주고 / 그 형태소마다 각각 자음모음을 분리해주는 함수\n",
        "def tokenize_by_jamo(s):\n",
        "    return [word_to_jamo(token) for token in mecab.morphs(s)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lg6P-Jeo3-7S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8e48fbb-6121-4d3a-8af6-ae3a3e0f77e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ㅅㅓㄴㅁㅜㄹ', 'ㅇㅛㅇ', 'ㅇㅡ-ㄹㅗ-', 'ㅃㅏㄹㄹㅣ-', 'ㅂㅏㄷ', 'ㅇㅏ-ㅅㅓ-', 'ㅈㅓㄴㄷㅏㄹ', 'ㅎㅐㅆㅇㅓ-ㅇㅑ-', 'ㅎㅏ-', 'ㄴㅡㄴ', 'ㅅㅏㅇㅍㅜㅁ', 'ㅇㅣ-', 'ㅇㅓㅆ', 'ㄴㅡㄴㄷㅔ-', 'ㅁㅓ-ㄱㅡ-', 'ㅋㅓㅂ', 'ㅁㅏㄴ', 'ㅇㅘ-ㅅㅓ-', 'ㄷㅏㅇㅎㅘㅇ', 'ㅎㅐㅆ', 'ㅅㅡㅂㄴㅣ-ㄷㅏ-', '.']\n"
          ]
        }
      ],
      "source": [
        "print(tokenize_by_jamo('선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다.'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xsmpYSY24E_L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bc58980-01e7-4845-8b96-1c5a2e5789e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200000/200000 [01:04<00:00, 3095.45it/s]\n"
          ]
        }
      ],
      "source": [
        "# 리뷰 데이터의 reviews 컬럼만을 가져와서 자모 분리\n",
        "tokenized_data = []\n",
        "\n",
        "for sample in tqdm(total_data['reviews'].to_numpy()):\n",
        "    tokenzied_sample = tokenize_by_jamo(sample) # 자소 단위 토큰화\n",
        "    tokenized_data.append(tokenzied_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LWbx6vn4u7R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d874fb1e-a6a1-48cb-833e-b08712efdcdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200000\n",
            "전처리 전: 택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고\n",
            "전처리 후: ['ㅌㅐㄱㅂㅐ-', 'ㄱㅏ-', 'ㅇㅓㅇㅁㅏㅇ', 'ㅇㅣ-', 'ㄴㅔ-', 'ㅇㅛㅇ', 'ㅈㅓ-ㅎㅢ-', 'ㅈㅣㅂ', 'ㅁㅣㅌ', 'ㅇㅔ-', 'ㅊㅡㅇ', 'ㅇㅔ-', 'ㅁㅏㄹ', 'ㄷㅗ-', 'ㅇㅓㅄㅇㅣ-', 'ㄴㅘ-ㄷㅜ-', 'ㄱㅗ-', 'ㄱㅏ-', 'ㄱㅗ-']\n"
          ]
        }
      ],
      "source": [
        "print(len(tokenized_data))\n",
        "print(\"전처리 전:\", total_data['reviews'][1])\n",
        "print(\"전처리 후:\", tokenized_data[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7xeSqF_5-jM"
      },
      "source": [
        "단어를 자모 분리한 것을 역으로 하여 자모 상태를 단어로 다시 결합시키는 함수도 정의해봅시다. 이는 단어의 코사인 유사도를 평가할 때 자모 분리가 된 상태가 아니라 단어 상태로 편리하게 보기 위함입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dg2U2hoF5-21"
      },
      "outputs": [],
      "source": [
        "def jamo_to_word(jamo_sequence):\n",
        "  tokenized_jamo = []\n",
        "  index = 0\n",
        "\n",
        "  # 1. 초기 입력\n",
        "  # jamo_sequence = 'ㄴㅏㅁㄷㅗㅇㅅㅐㅇ'\n",
        "\n",
        "  while index < len(jamo_sequence):\n",
        "    # 문자가 한글(정상적인 자모)이 아닐 경우\n",
        "    if not hgtk.checker.is_hangul(jamo_sequence[index]):\n",
        "      tokenized_jamo.append(jamo_sequence[index])\n",
        "      index = index + 1\n",
        "\n",
        "    # 문자가 정상적인 자모라면 초성, 중성, 종성을 하나의 토큰으로 간주.\n",
        "    # 3개씩 tokenized_jamo에 넣기\n",
        "    else:\n",
        "      tokenized_jamo.append(jamo_sequence[index:index + 3])\n",
        "      index = index + 3\n",
        "\n",
        "  # 2. 자모 단위 토큰화 완료\n",
        "  # tokenized_jamo : ['ㄴㅏㅁ', 'ㄷㅗㅇ', 'ㅅㅐㅇ']\n",
        "\n",
        "  word = ''\n",
        "  try:\n",
        "    for jamo in tokenized_jamo:\n",
        "\n",
        "      # 초성, 중성, 종성의 묶음으로 추정되는 경우\n",
        "      if len(jamo) == 3:\n",
        "        if jamo[2] == \"-\":\n",
        "          # 종성이 존재하지 않는 경우\n",
        "          word = word + hgtk.letter.compose(jamo[0], jamo[1])\n",
        "        else:\n",
        "          # 종성이 존재하는 경우\n",
        "          word = word + hgtk.letter.compose(jamo[0], jamo[1], jamo[2])\n",
        "      # 한글이 아닌 경우\n",
        "      else:\n",
        "        word = word + jamo\n",
        "\n",
        "  # 복원 중(hgtk.letter.compose) 에러 발생 시 초기 입력 리턴.\n",
        "  # 복원이 불가능한 경우 예시) 'ㄴ!ㅁㄷㅗㅇㅅㅐㅇ'\n",
        "  except Exception as exception:\n",
        "    if type(exception).__name__ == 'NotHangulException':\n",
        "      return jamo_sequence\n",
        "\n",
        "  # 3. 단어로 복원 완료\n",
        "  # word : '남동생'\n",
        "\n",
        "  return word"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyyqJpte8TWa"
      },
      "source": [
        "## 4. FastText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnQCv2mK6vw1"
      },
      "outputs": [],
      "source": [
        "import fasttext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-27ntoZR8Si6"
      },
      "source": [
        "fasttext를 실행하기에 앞서 훈련 대상인 단어들을 txt 파일로 준비해둬야 합니다. 따라서 `tokenized_data.txt`라는 파일을 쓰기 모드(w)로 생성해주고 앞서 전처리한 `tokenized_data`를 입력해줍니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avmb1eqc6wwf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "732d95dd-9ba5-41aa-e4e4-e599458e2a2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200000/200000 [00:00<00:00, 317755.12 line/s]\n"
          ]
        }
      ],
      "source": [
        "# 'w' 모드는 파일을 쓰기 모드로 연다. 파일이 존재하지 않으면 새로 생성, 이미 존재하면 기존 내용을 덮어쓰기\n",
        "with open('tokenized_data.txt', 'w') as out:\n",
        "  for line in tqdm(tokenized_data, unit=' line'):\n",
        "    out.write(' '.join(line) + '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4NkTSg580Ze"
      },
      "source": [
        "아래처럼 `train_unsupeviesd` 함수는 훈련을 시켜주는 함수입니다. 인자로 훈련할 단어가 담긴 txt 파일을 지정하고 model을 `cbow`나 `skipgram` 중에 하나를 고르면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAbtngsx8xZ5"
      },
      "outputs": [],
      "source": [
        "# fastText 라이브러리를 사용하여 주어진 텍스트 데이터에서 단어 임베딩을 학습\n",
        "# cbow (Continuous Bag of Words)는 주변 단어들을 보고 중심 단어를 예측하는 방식\n",
        "# skip-gram은 중심 단어를 이용해 주변 단어들을 예측하는 방식\n",
        "model = fasttext.train_unsupervised('tokenized_data.txt', model='cbow')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGlu2L8F9Rsk"
      },
      "outputs": [],
      "source": [
        "model.save_model(\"fasttext.bin\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjrJe6l997N9"
      },
      "outputs": [],
      "source": [
        "model = fasttext.load_model(\"fasttext.bin\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0yY3vUqj9-ou",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8137b224-37af-4af6-8712-c12f426de062"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.13569409,  0.4623273 , -0.01305818,  0.091923  ,  0.8884961 ,\n",
              "       -0.70672673,  0.48292375, -0.3646574 ,  0.6182261 , -0.3731981 ,\n",
              "        0.5740161 , -0.32798734,  0.03288039,  0.21142   ,  0.2692521 ,\n",
              "       -0.34768972,  0.8025778 ,  0.48652577,  0.0793114 , -0.47609842,\n",
              "        0.08217715, -0.73614717, -0.21808197, -0.6572467 , -0.62725055,\n",
              "       -0.7788283 ,  0.9942148 ,  0.4799049 ,  0.45053965,  0.1581779 ,\n",
              "       -0.02743168, -1.8400221 ,  0.32926726,  0.39769325,  0.50863045,\n",
              "       -0.04471757, -0.03672473, -0.37270263, -0.51179665,  0.7603618 ,\n",
              "        0.7526085 , -0.09775814, -0.4021288 ,  1.3540925 , -0.05883694,\n",
              "       -0.04220911,  1.1076512 , -0.02282269, -0.3939666 ,  0.18986136,\n",
              "       -0.08131975,  0.06813409,  0.29437637, -0.35955757, -0.33949754,\n",
              "       -0.8908166 ,  0.23099631, -0.47223258,  0.03086808,  0.41188768,\n",
              "        0.07624658,  0.30248633,  0.71543837,  0.19763573,  0.0247907 ,\n",
              "       -0.5042291 ,  0.03791764, -0.2635259 , -0.5861881 , -0.7584387 ,\n",
              "        0.9468459 , -0.93265635,  0.17058255, -0.5261078 ,  0.26468325,\n",
              "        0.0740387 , -0.14515692,  0.7277668 ,  0.36025977,  0.4687432 ,\n",
              "        1.0063089 , -0.36477977,  0.39107305,  0.04073997,  1.2399262 ,\n",
              "       -0.14167798, -0.13344796, -0.20246269,  0.54271346, -0.65256983,\n",
              "        0.25297537,  0.06691516, -0.19940877, -0.5613759 ,  0.18420064,\n",
              "        1.3595666 , -0.05418065, -0.27165273,  0.19334605,  0.431546  ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# fastText 모델을 사용하여 주어진 단어 '남동생'의 임베딩 벡터를 구하기\n",
        "model[word_to_jamo('남동생')] # 'ㄴㅏㅁㄷㅗㅇㅅㅐㅇ'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rdJZgey-B72"
      },
      "source": [
        "`get_nearest_neighbors` 함수를 사용하여 '남동생'이라는 단어와 가장 유사도가 높은 단어들(자모 분리된 상태)을 k개만큼 출력해줍니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edTwzcQL9_vd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "672b1b69-aad7-43e1-c1b8-3ff5bab3ca92"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.8806344270706177, 'ㄷㅗㅇㅅㅐㅇ'),\n",
              " (0.8377861380577087, 'ㄴㅏㅁㅊㅣㄴ'),\n",
              " (0.774063229560852, 'ㄴㅏㅁㅍㅕㄴ'),\n",
              " (0.760077953338623, 'ㅅㅐㅇㅇㅣㄹ'),\n",
              " (0.7322480082511902, 'ㅊㅣㄴㄱㅜ-'),\n",
              " (0.7112826704978943, 'ㅈㅗ-ㅋㅏ-'),\n",
              " (0.7102761268615723, 'ㅈㅜㅇㅎㅏㄱㅅㅐㅇ'),\n",
              " (0.7087782025337219, 'ㅎㅏㄱㅅㅐㅇ'),\n",
              " (0.7076780200004578, 'ㄴㅏㄴㅅㅐㅇ'),\n",
              " (0.7012639045715332, 'ㄴㅏㅁㅇㅏ-')]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "model.get_nearest_neighbors(word_to_jamo('남동생'), k=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAA_9Nz--Kuu"
      },
      "source": [
        "앞서 만든 `jamo_to_word`로 가독성이 좋게 출력해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7Um5Sgh-QC-"
      },
      "outputs": [],
      "source": [
        "def transform(word_sequence):\n",
        "  return [(jamo_to_word(word), similarity) for (similarity, word) in word_sequence]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rvV7Sx--Q74",
        "outputId": "42912ec6-62ef-41be-9e17-fa6b0c367190"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('동생', 0.8806344270706177), ('남친', 0.8377861380577087), ('남편', 0.774063229560852), ('생일', 0.760077953338623), ('친구', 0.7322480082511902), ('조카', 0.7112826704978943), ('중학생', 0.7102761268615723), ('학생', 0.7087782025337219), ('난생', 0.7076780200004578), ('남아', 0.7012639045715332)]\n",
            "[('구매처', 0.8529492020606995), ('구입', 0.8159204125404358), ('주문', 0.7491198778152466), ('주문건', 0.6805321574211121), ('헤매', 0.6214126348495483), ('주문서', 0.6121081113815308), ('구매자', 0.6027916073799133), ('구메', 0.5934557914733887), ('구토', 0.5757238268852234), ('재', 0.5701424479484558)]\n",
            "[('배송지', 0.8234754204750061), ('매달', 0.7856132984161377), ('깨달', 0.7802218198776245), ('메달', 0.7598093152046204), ('운송장', 0.7575247287750244), ('송장', 0.7519562840461731), ('배소', 0.738389790058136), ('택배', 0.7370787858963013), ('배송', 0.729705810546875), ('운송', 0.7214983105659485)]\n"
          ]
        }
      ],
      "source": [
        "print(transform(model.get_nearest_neighbors(word_to_jamo('남동생'), k=10)))\n",
        "print(transform(model.get_nearest_neighbors(word_to_jamo('구매'), k=10)))\n",
        "print(transform(model.get_nearest_neighbors(word_to_jamo('배달'), k=10)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsHeruLf-o6A"
      },
      "source": [
        "## 5. Word2Vec\n",
        "\n",
        "![image.png](attachment:image.png)\n",
        "이제 word2vec를 사용하여 자모 단위로 분리하는 것이 아닌 단어 단위로 분리하여 임베딩 벡터를 생성해볼 것입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6ZraaNk-0uZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cc75c7c-cae0-4d48-cf52-1cb12731f0df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200000/200000 [00:23<00:00, 8354.06it/s]\n"
          ]
        }
      ],
      "source": [
        "# 간단하게 불용어 정의\n",
        "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
        "\n",
        "tokenized_data2 = []\n",
        "for sentence in tqdm(total_data['reviews'].to_list()):\n",
        "    tokenized_sentence = mecab.morphs(sentence) # 토큰화\n",
        "    stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords] # 불용어 제거\n",
        "    tokenized_data2.append(stopwords_removed_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSGnJMfd_YGc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "730a219c-aa79-4316-d969-2c705ba9a475"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word2vec용 데이터: ['배공', '빠르', '고', '굿']\n",
            "fasttext용 데이터: ['ㅂㅐ-ㄱㅗㅇ', 'ㅃㅏ-ㄹㅡ-', 'ㄱㅗ-', 'ㄱㅜㅅ']\n"
          ]
        }
      ],
      "source": [
        "print(\"word2vec용 데이터:\", tokenized_data2[0])\n",
        "print(\"fasttext용 데이터:\", tokenized_data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgfuDFLD_KTy"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "model2 = Word2Vec(sentences = tokenized_data2, vector_size = 1000, window = 5, min_count = 5, workers = 4, sg = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PccU_FKd_MpB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0010abf2-51b2-490b-f829-209da5bc9ce7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15004, 1000)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "# 완성된 임베딩 매트릭스의 크기 확인\n",
        "# 단어의 총 개수는 15005개이고 벡터 차원은 1000으로 축소되었다.\n",
        "model2.wv.vectors.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S64jTHof_Ov3"
      },
      "source": [
        "## 6. FastText와 Word2Vec 결과 비교"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxlPe5plBPoR"
      },
      "source": [
        "### **Q1) 남동생과 주문 두 단어를 input으로 넣고 결과를 비교한 뒤 해석해보세요**\n",
        "\n",
        "*(Hint: 유사도, 단어의 의미, 단어의 생김새 등을 고려해 볼 수 있습니다)*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VL9lr6BAi6t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c3f010c-2e68-4e45-b832-c43a0b95928d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastText 유사도: [('동생', 0.8806344270706177), ('남친', 0.8377861380577087), ('남편', 0.774063229560852), ('생일', 0.760077953338623), ('친구', 0.7322480082511902), ('조카', 0.7112826704978943), ('중학생', 0.7102761268615723), ('학생', 0.7087782025337219), ('난생', 0.7076780200004578), ('남아', 0.7012639045715332)]\n",
            "Word2Vec 유사도: [('동생', 0.6766485571861267), ('언니', 0.6721143126487732), ('시어머님', 0.6678840517997742), ('친정아버지', 0.6613014340400696), ('외할머니', 0.6601095795631409), ('오빠', 0.65887451171875), ('욕먹', 0.6560006141662598), ('어머님께', 0.6548600196838379), ('나눠', 0.6529167890548706), ('그분', 0.6441274285316467)]\n"
          ]
        }
      ],
      "source": [
        "print(\"FastText 유사도:\", transform(model.get_nearest_neighbors(word_to_jamo('남동생'), k=10)))\n",
        "print(\"Word2Vec 유사도:\", model2.wv.most_similar(\"남동생\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3lAnif5BWay",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6314c45f-526c-41c2-89e8-8b92e3e4d319"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastText 유사도: [('주문건', 0.9132550954818726), ('주문서', 0.8433078527450562), ('구입', 0.7607749700546265), ('구매', 0.7491196393966675), ('주문자', 0.7418688535690308), ('주무시', 0.7305777668952942), ('주무', 0.7111703753471375), ('구매처', 0.7004423141479492), ('시킨', 0.6868689060211182), ('시켰었', 0.6680076718330383)]\n",
            "Word2Vec 유사도: [('구매', 0.8210728168487549), ('구입', 0.8168444633483887), ('선택', 0.6400911211967468), ('결제', 0.5825795531272888), ('시켰', 0.5556408166885376), ('장만', 0.5377300381660461), ('준비', 0.5360223054885864), ('시킨', 0.5147585272789001), ('이용', 0.5071157813072205), ('도착', 0.5064150094985962)]\n"
          ]
        }
      ],
      "source": [
        "print(\"FastText 유사도:\", transform(model.get_nearest_neighbors(word_to_jamo('주문'), k=10)))\n",
        "print(\"Word2Vec 유사도:\", model2.wv.most_similar(\"주문\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGJZGHcxA52j"
      },
      "source": [
        "**Your Inference:**\n",
        "\n",
        "FastText의 경우, 비슷한 의미를 가진 단어들을 잘 나타냈긴 했지만, 전반적으로 비슷한 생김새를 가진 단어가 많이 나옴.\n",
        "\n",
        "이는, 단어가 아닌 자모 단위까지 분석하여 구조적 유사성을 위주로 학습한 결과라고 할 수 있음.\n",
        "\n",
        "Word2Vec의 경우도 비슷한 의미를 가진 단어들을 잘 나타냈는데, FastText에 비해서 생김새가 다른 단어들도 많이 나타난 것을 알 수 있다. 이는, 단어를 기반으로 학습하였기 때문에, 의미적 유사성, 맥락을 위주로 학습한 결과라고 할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "US6x_FiIryoM"
      },
      "source": [
        "### **Q2) Fasttext가 Word2Vec보다 항상 성능이 나은지 다양한 input을 넣어서 시도해보세요**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLkz-ZalsB2v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90e7dd8d-da8a-4995-8423-ae9dac8e4792"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastText 유사도: [('모니터', 0.8663520812988281), ('히터', 0.8379722833633423), ('모터', 0.8215763568878174), ('카운터', 0.797143816947937), ('충전기', 0.7958075404167175), ('글리터', 0.7938380837440491), ('콘센트', 0.7892261743545532), ('이어폰', 0.7890419363975525), ('데이터', 0.7829801440238953), ('이터', 0.7807217836380005)]\n",
            "Word2Vec 유사도: [('블루투스', 0.8014799356460571), ('모니터', 0.761049211025238), ('전기', 0.7493318915367126), ('TV', 0.7485159635543823), ('스피커', 0.7472842335700989), ('핸드폰', 0.7411299347877502), ('이어폰', 0.7395033836364746), ('잭', 0.7329862713813782), ('pc', 0.7253855466842651), ('에어컨', 0.7072665691375732)]\n"
          ]
        }
      ],
      "source": [
        "print(\"FastText 유사도:\", transform(model.get_nearest_neighbors(word_to_jamo('컴퓨터'), k=10)))\n",
        "print(\"Word2Vec 유사도:\", model2.wv.most_similar(\"컴퓨터\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"FastText 유사도:\", transform(model.get_nearest_neighbors(word_to_jamo('택배'), k=10)))\n",
        "print(\"Word2Vec 유사도:\", model2.wv.most_similar(\"택배\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQkAsykWTQa5",
        "outputId": "206d8a56-57df-4656-fa03-27dc31994494"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastText 유사도: [('백배', 0.9107794165611267), ('배송지', 0.7746958136558533), ('배달', 0.7370787858963013), ('송장', 0.7266694903373718), ('운송장', 0.707958996295929), ('송사', 0.6952088475227356), ('똥배', 0.6943500638008118), ('송송', 0.6911389231681824), ('목배', 0.6817958950996399), ('업체', 0.6805452704429626)]\n",
            "Word2Vec 유사도: [('배달', 0.6749909520149231), ('문자', 0.616783857345581), ('배송', 0.5985751152038574), ('발송', 0.59242844581604), ('연락', 0.5748752355575562), ('물건', 0.5731770396232605), ('전화', 0.5659687519073486), ('대응', 0.5639975666999817), ('업체', 0.5589093565940857), ('번호', 0.5566214919090271)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"FastText 유사도:\", transform(model.get_nearest_neighbors(word_to_jamo('옷'), k=10)))\n",
        "print(\"Word2Vec 유사도:\", model2.wv.most_similar(\"옷\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAV6IxSTThwr",
        "outputId": "bb87e914-c03a-4752-d43c-61c8428c67f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastText 유사도: [('흰옷', 0.9175217747688293), ('윗옷', 0.8901131749153137), ('겉옷', 0.8580032587051392), ('잠옷', 0.8109560012817383), ('속옷', 0.7771564722061157), ('옷감', 0.7383854389190674), ('바질', 0.7061029672622681), ('여름옷', 0.6965909600257874), ('겨울옷', 0.691399097442627), ('옷핀', 0.6799166202545166)]\n",
            "Word2Vec 유사도: [('바지', 0.6959079504013062), ('속옷', 0.6814422607421875), ('이불', 0.6637142300605774), ('신발', 0.6267321705818176), ('양말', 0.6188209056854248), ('치마', 0.614963173866272), ('레깅스', 0.6054590344429016), ('원피스', 0.5935451984405518), ('팬티', 0.5920928716659546), ('옷감', 0.5810904502868652)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"FastText 유사도:\", transform(model.get_nearest_neighbors(word_to_jamo('이어폰'), k=10)))\n",
        "print(\"Word2Vec 유사도:\", model2.wv.most_similar(\"이어폰\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_EWP6uwToLn",
        "outputId": "4fe51751-cdb0-4945-932f-3327f7597793"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastText 유사도: [('헤드폰', 0.8408994078636169), ('핸드폰', 0.8261727690696716), ('휴대폰', 0.7989616990089417), ('연결선', 0.7909033298492432), ('컴퓨터', 0.7890421152114868), ('연결대', 0.7824413776397705), ('케이블', 0.7760635614395142), ('충전기', 0.7743161916732788), ('연결', 0.7700163125991821), ('인식', 0.7672682404518127)]\n",
            "Word2Vec 유사도: [('잭', 0.8103588819503784), ('블루투스', 0.805679440498352), ('충전기', 0.7931431531906128), ('폰', 0.7911986708641052), ('케이블', 0.7664262056350708), ('단자', 0.7616552710533142), ('스피커', 0.7588788866996765), ('컴퓨터', 0.7395035028457642), ('카메라', 0.7248949408531189), ('usb', 0.7234473824501038)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4VZ-I34sOXj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "78412552-50ac-4db6-febb-45a54a84d779"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastText 유사도: [('카타', 0.9112368226051331), ('리코타', 0.8275164365768433), ('쏘나타', 0.7883312106132507), ('타카', 0.7859053015708923), ('오타', 0.7774915099143982), ('타피오카', 0.7522192597389221), ('홍차', 0.7415450215339661), ('아타', 0.7391024827957153), ('타', 0.7375775575637817), ('브리타', 0.7355550527572632)]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"Key '콤퓨타' not present in vocabulary\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-2aa998db7918>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"FastText 유사도:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_nearest_neighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_to_jamo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'콤퓨타'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Word2Vec 유사도:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"콤퓨타\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m         \u001b[0;31m# compute the weighted average of all keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mean_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_normalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpost_normalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m         all_keys = [\n\u001b[1;32m    843\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_KEY_TYPES\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_index_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_mean_vector\u001b[0;34m(self, keys, weights, pre_normalize, post_normalize, ignore_missing)\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mtotal_weight\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mignore_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Key '{key}' not present in vocabulary\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtotal_weight\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"Key '콤퓨타' not present in vocabulary\""
          ]
        }
      ],
      "source": [
        "print(\"FastText 유사도:\", transform(model.get_nearest_neighbors(word_to_jamo('콤퓨타'), k=10)))\n",
        "print(\"Word2Vec 유사도:\", model2.wv.most_similar(\"콤퓨타\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"FastText 유사도:\", transform(model.get_nearest_neighbors(word_to_jamo('택배아저씨'), k=10)))\n",
        "print(\"Word2Vec 유사도:\", model2.wv.most_similar(\"택배아저씨\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "6SgvblY9TcYt",
        "outputId": "d6896dc1-f0f0-422d-b8a6-8cbf3c1b6480"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastText 유사도: [('택배', 0.9025048613548279), ('아저씨', 0.8464900851249695), ('백배', 0.781571626663208), ('경비실', 0.7434183955192566), ('cj', 0.7237663269042969), ('회사', 0.7135401964187622), ('송사', 0.7132192850112915), ('송장', 0.7123468518257141), ('배송지', 0.7110281586647034), ('운송장', 0.7094765305519104)]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"Key '택배아저씨' not present in vocabulary\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-21de3fc1f597>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"FastText 유사도:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_nearest_neighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_to_jamo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'택배아저씨'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Word2Vec 유사도:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"택배아저씨\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m         \u001b[0;31m# compute the weighted average of all keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mean_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_normalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpost_normalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m         all_keys = [\n\u001b[1;32m    843\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_KEY_TYPES\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_index_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_mean_vector\u001b[0;34m(self, keys, weights, pre_normalize, post_normalize, ignore_missing)\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mtotal_weight\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mignore_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Key '{key}' not present in vocabulary\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtotal_weight\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"Key '택배아저씨' not present in vocabulary\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"FastText 유사도:\", transform(model.get_nearest_neighbors(word_to_jamo('전자기기'), k=10)))\n",
        "print(\"Word2Vec 유사도:\", model2.wv.most_similar(\"전자기기\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "YdjzLd2oToPJ",
        "outputId": "a71e3625-a775-437a-9a0c-65a8f8c59da5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastText 유사도: [('계기', 0.8598759770393372), ('공유기', 0.8522873520851135), ('대기', 0.8467065095901489), ('획기', 0.8457708954811096), ('갑자기', 0.8431621789932251), ('뚝배기', 0.8365164399147034), ('전기', 0.8345414400100708), ('소화기', 0.8321074843406677), ('악기', 0.8308396935462952), ('기기', 0.8302286863327026)]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"Key '전자기기' not present in vocabulary\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-62c79709ec24>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"FastText 유사도:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_nearest_neighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_to_jamo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'전자기기'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Word2Vec 유사도:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"전자기기\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m         \u001b[0;31m# compute the weighted average of all keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mean_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_normalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpost_normalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m         all_keys = [\n\u001b[1;32m    843\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_KEY_TYPES\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_index_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_mean_vector\u001b[0;34m(self, keys, weights, pre_normalize, post_normalize, ignore_missing)\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mtotal_weight\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mignore_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Key '{key}' not present in vocabulary\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtotal_weight\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"Key '전자기기' not present in vocabulary\""
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUyyS7GfsSha"
      },
      "source": [
        "**Your Inference:**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "데이터베이스에 있는 단어의 경우, FastText은 비슷한 생김새를 가지는 단어들을 위주로 나타내지만, Word2Vec이 FastText보다 훨씬 더 의미적으로 비슷하고 다양한 단어들을 결과로 내는 것을 알 수 있다.\n",
        "\n",
        "하지만, Word2Vec의 경우, 데이터베이스에 없는 단어에서는 에러를 보이는데, 이는 Word2Vec 모델의 사전에 '전자기기'와 같은 단어가 없어, 벡터화 할 수 없기에 유사도를 계산하지 못한 결과라고 할 수 있다.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "결론적으로, 자모 단위로 분해해 처리하는 FastText는 학습데이터에 없더라도, 자모 단위로 분석하여 유사성을 계산하여, 형태적으로 유사한 단어들을 제공할 수 있기에 활용하기에 더 좋을 수 있다.\n",
        "\n",
        "하지만, 학습데이터에 있는 단어의 경우, Word2Vec가 FastText보다 훨씬 더 의미적, 맥락적으로 비슷한 단어들을 나타내는 것을 확인하였기에, 전반적인 성능은 Word2Vec이 뛰어나다고 판단된다.\n",
        "\n",
        "따라서, 위의 문제점을 해결하기 위해 Word2Vec 모델을 활용하되, 해당 모델의 사전을 크게 확장하는 방법이 좋을 것으로 보이고, 사전에 없는 단어여서 Word2Vec을 사용할 수 없는 경우에, FastText를 활용하는 방법이 좋다고 생각된다."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v2O4hUZAo7aT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}