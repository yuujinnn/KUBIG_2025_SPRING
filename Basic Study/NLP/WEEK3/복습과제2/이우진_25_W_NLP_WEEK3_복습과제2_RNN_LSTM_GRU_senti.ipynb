{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1sviZfjra6c"
      },
      "source": [
        "참고 (딥러닝을 이용한 자연어 처리)\n",
        ": https://wikidocs.net/94600\n",
        "\n",
        "위 링크에는 keras framework로 신경망을 구현한 반면, 이번 과제에서는 **pytorch** framework로 구현해보도록 합니다.\n",
        "\n",
        "참고 : https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_recurrent_neuralnetwork/\n",
        "https://wonhwa.tistory.com/35"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJdUylezMQ19",
        "outputId": "c6db34f4-ce0c-4d29-f2c0-3595e33e7771"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3Piwi4SkyZs",
        "outputId": "1357a0b9-1e68-4258-abfd-37a2a6a4fb11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda is available.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"{device}\" \" is available.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VWSo5CAjxu8"
      },
      "source": [
        "### 데이터 불러오기 (네이버 쇼핑 리뷰 감성 분석 데이터)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IXiir7_oFO6",
        "outputId": "9d01f07a-a61d-4430-c076-a2c3cbf0720a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.11/dist-packages (0.6.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from konlpy) (1.5.2)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from konlpy) (5.3.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.11/dist-packages (from konlpy) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from JPype1>=0.7.0->konlpy) (24.2)\n",
            "Requirement already satisfied: mecab-python in /usr/local/lib/python3.11/dist-packages (1.0.0)\n",
            "Requirement already satisfied: mecab-python3 in /usr/local/lib/python3.11/dist-packages (from mecab-python) (1.0.10)\n",
            "mecab-ko is already installed\n",
            "mecab-ko-dic is already installed\n",
            "mecab-python is already installed\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "!pip install konlpy\n",
        "!pip install mecab-python\n",
        "!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "312yGF-nn-7Z"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "from collections import Counter\n",
        "from konlpy.tag import Mecab\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1XyR9D-oSsJ",
        "outputId": "adc7c660-3c64-463d-f7ea-0ab746ef683c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "리뷰 개수 :  200000\n"
          ]
        }
      ],
      "source": [
        "# 데이터 로드하기\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/bab2min/corpus/master/sentiment/naver_shopping.txt\", filename=\"ratings_total.txt\")\n",
        "total_data = pd.read_table('ratings_total.txt', names = ['ratings', 'reviews'])\n",
        "\n",
        "# 데이터 개수 확인\n",
        "print('리뷰 개수 : ', len(total_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "w_uJez_mol6E",
        "outputId": "b3032dc7-eb51-4d26-dac2-b8eb98632fd0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   ratings                                            reviews\n",
              "0        5                                            배공빠르고 굿\n",
              "1        2                      택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고\n",
              "2        5  아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...\n",
              "3        2  선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...\n",
              "4        5                  민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-66b605e6-0ee9-46b4-973e-e8a73030ba29\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ratings</th>\n",
              "      <th>reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>배공빠르고 굿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-66b605e6-0ee9-46b4-973e-e8a73030ba29')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-66b605e6-0ee9-46b4-973e-e8a73030ba29 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-66b605e6-0ee9-46b4-973e-e8a73030ba29');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9c75d70f-2ff3-4112-b6cd-aba5efa51b37\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9c75d70f-2ff3-4112-b6cd-aba5efa51b37')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9c75d70f-2ff3-4112-b6cd-aba5efa51b37 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"total_data[:5] # \\uc0c1\\uc704 5\\uac1c \\ub370\\uc774\\ud130\\ub9cc \\uc0d8\\ud50c\\ub85c \\ud655\\uc778\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"ratings\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 2,\n        \"max\": 5,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reviews\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\ud0dd\\ubc30\\uac00 \\uc5c9\\ub9dd\\uc774\\ub124\\uc6a9 \\uc800\\ud76c\\uc9d1 \\ubc11\\uc5d0\\uce35\\uc5d0 \\ub9d0\\ub3c4\\uc5c6\\uc774 \\ub194\\ub450\\uace0\\uac00\\uace0\",\n          \"\\ubbfc\\ud2b8\\uc0c9\\uc0c1 \\uc608\\ubed0\\uc694. \\uc606 \\uc190\\uc7a1\\uc774\\ub294 \\uac70\\ub294 \\uc6a9\\ub3c4\\ub85c\\ub3c4 \\uc0ac\\uc6a9\\ub418\\ub124\\uc694 \\u314e\\u314e\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "total_data[:5] # 상위 5개 데이터만 샘플로 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1R4QJEaxorat"
      },
      "outputs": [],
      "source": [
        "# 감성 분석을 위한 라벨링\n",
        "total_data['label'] = np.select([total_data.ratings > 3], [1], default=0) # 4,5점은 긍정 1 / 1,2 점은 부정 0 으로 라벨링\n",
        "total_data.drop_duplicates(subset=['reviews'], inplace=True) # 중복 제거\n",
        "\n",
        "# 훈련 데이터와 테스트 데이터 split\n",
        "train_data, test_data = train_test_split(total_data, test_size = 0.2, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "6lI6XJRUqTIp",
        "outputId": "0374232f-fca4-4104-b4c6-c3a093d1c552"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "1    80003\n",
              "0    79923\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>80003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>79923</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "train_data['label'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMftA9UKqiBl"
      },
      "source": [
        "### 데이터 정제 및 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5JDUsBpqj45",
        "outputId": "8ba18601-dfa0-49b5-b67e-dd2aa70e5848"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-c7c78b9ac4f4>:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  train_data['reviews'].replace('', np.nan, inplace=True)\n",
            "<ipython-input-9-c7c78b9ac4f4>:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  test_data['reviews'].replace('', np.nan, inplace=True) # 공백은 Null 값으로 변경\n"
          ]
        }
      ],
      "source": [
        "# 한글과 공백을 제외하고 모두 제거 (train)\n",
        "# [^ㄱ-ㅎㅏ-ㅣ가-힣 ]: 정규 표현식으로, 한글(모음과 자음)과 띄어쓰기를 제외한 문자들을 매칭\n",
        "train_data['reviews'] = train_data['reviews'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
        "# train_data['reviews'] 열에서 빈 문자열('')을 NaN(결측치)으로 변경\n",
        "train_data['reviews'].replace('', np.nan, inplace=True)\n",
        "\n",
        "# test data에도 동일하게 적용\n",
        "test_data.drop_duplicates(subset = ['reviews'], inplace=True) # 중복 제거\n",
        "test_data['reviews'] = test_data['reviews'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
        "test_data['reviews'].replace('', np.nan, inplace=True) # 공백은 Null 값으로 변경\n",
        "test_data = test_data.dropna(how='any') # Null 값 제거"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cn6IM4UQq8ad"
      },
      "source": [
        "### 토큰화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4u0NrFSaq9vd"
      },
      "outputs": [],
      "source": [
        "# Mecab 모델로 형태소 분석 및 토큰화\n",
        "mecab = Mecab()\n",
        "\n",
        "# 불용어 설정\n",
        "# stopword.txt 파일이 저장된 경로를 정확히 입력해주세요\n",
        "with open('/content/drive/MyDrive/NLP/WEEK1/예습과제2/stopword.txt') as f:\n",
        "    list_file = f.readlines()\n",
        "\n",
        "stopwords_list = []\n",
        "for stopword in list_file:\n",
        "  stopwords = re.sub('[\\n]', '', stopword)\n",
        "  stopwords_list.append(stopwords)\n",
        "\n",
        "# train data 토큰화\n",
        "train_data['tokenized'] = train_data['reviews'].apply(mecab.morphs)\n",
        "train_data['tokenized'] = train_data['tokenized'].apply(lambda x: [item for item in x if item not in stopwords_list])\n",
        "\n",
        "# test data 토큰화\n",
        "test_data['tokenized'] = test_data['reviews'].apply(mecab.morphs)\n",
        "test_data['tokenized'] = test_data['tokenized'].apply(lambda x: [item for item in x if item not in stopwords_list])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CD_HiUHroCe"
      },
      "source": [
        "### 정수 인코딩"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4H9Bu8yxr03N"
      },
      "outputs": [],
      "source": [
        "# train과 test를 위한 X,Y data 분류\n",
        "\n",
        "X_train = train_data['tokenized'].values\n",
        "y_train = train_data['label'].values\n",
        "X_test= test_data['tokenized'].values\n",
        "y_test = test_data['label'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "aiQQp7KCrpR6"
      },
      "outputs": [],
      "source": [
        "# 단어 집합 생성 및 정수 인코딩\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "nUz8VtqgsFjB"
      },
      "outputs": [],
      "source": [
        "# vocab_size 설정\n",
        "vocab_size = len(tokenizer.word_index)\n",
        "\n",
        "# 텍스트 시퀀스 -> 정수 시퀀스\n",
        "tokenizer = Tokenizer(vocab_size, oov_token = 'OOV')\n",
        "# oov_token='OOV'는 Out-Of-Vocabulary(단어 집합에 없는 단어)에 대해 'OOV'라는 토큰을 사용하도록 설정\n",
        "\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYZGDvYhsbF2"
      },
      "source": [
        "### 패딩\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WULaQy5-scVq",
        "outputId": "883efe01-9acf-400d-d3fa-276e8830d4fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "리뷰의 최대 길이 : 88\n",
            "리뷰의 평균 길이 : 17.154021234821105\n"
          ]
        }
      ],
      "source": [
        "print('리뷰의 최대 길이 :',max(len(review) for review in X_train))\n",
        "print('리뷰의 평균 길이 :',sum(map(len, X_train))/len(X_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "fmlo_6gVO3az",
        "outputId": "b546cd48-469e-418e-a5af-b0c02ca014a2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "num_tokens = [len(review) for review in X_train]\n",
        "\n",
        "plt.title('all text length')\n",
        "plt.hist(num_tokens, bins=30)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44WPTfENOWAa",
        "outputId": "f68e2ac9-5b39-4c8c-9eb7-2b85a02e9a4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 샘플 중 길이가 40 이하인 샘플의 비율: 0.9337005865212661\n"
          ]
        }
      ],
      "source": [
        "select_length = 40\n",
        "\n",
        "def below_threshold_len(max_len, nested_list):\n",
        "    cnt = 0\n",
        "    for s in nested_list:\n",
        "        if(len(s) <= max_len):\n",
        "            cnt = cnt + 1\n",
        "\n",
        "    print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))\n",
        "\n",
        "below_threshold_len(select_length, X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "LiyYv--EsjAO"
      },
      "outputs": [],
      "source": [
        "# 최대 길이를 40으로 잡고 패딩\n",
        "# 텍스트 데이터를 일정한 길이로 맞추기 위해 패딩(padding)을 적용\n",
        "# 시퀀스가 max_len보다 짧으면 앞부분에 0을 추가하여 길이를 맞추고, max_len보다 길면 뒤에서 잘라내서 길이를 맞춘다.\n",
        "max_len = 40\n",
        "X_train = pad_sequences(X_train, maxlen=max_len)\n",
        "X_test = pad_sequences(X_test, maxlen=max_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvBULJ9G7ckL"
      },
      "source": [
        "### 퀴즈\n",
        "\n",
        "문제: 패딩을 하는 이유는 무엇일까요? (어떤 경우에 사용하는지 생각해보세요)\n",
        "\n",
        "답변:\n",
        "\n",
        "패딩(padding)은 주로 입력 데이터의 길이가 일정하지 않은 경우에 사용\n",
        "\n",
        "즉, 모델에 입력하기 전에 모든 데이터를 동일한 길이로 맞추기 위해 패딩을 사용\n",
        "\n",
        "<br>\n",
        "\n",
        "신경망 모델은 배치 처리로 데이터를 한 번에 처리 (모든 시퀀스의 길이가 동일해야 배치 단위로 데이터를 처리) -> 특히 LSTM이나 GRU 같은 순차적 모델들은 고정된 입력 크기를 요구"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "NZPf38qXttio"
      },
      "outputs": [],
      "source": [
        "# model 변경 함수\n",
        "def get_model(model, model_params):\n",
        "    models = {\n",
        "        \"rnn\": RNNModel,\n",
        "        \"lstm\": LSTMModel,\n",
        "        \"gru\": GRUModel,\n",
        "    }\n",
        "    return models.get(model.lower())(**model_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXExaNzZLUG1"
      },
      "source": [
        "### DataLoader 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "IyVTAop2L9Kv"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class LabeledNumpyArrayDataset(Dataset):\n",
        "    def __init__(self, numpy_data, numpy_labels, transform=None):\n",
        "        self.data = numpy_data\n",
        "        self.labels = numpy_labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sample = self.data[index]\n",
        "        label = self.labels[index]\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ROX3dxWBLWA2"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "\n",
        "# 레이블링된 데이터셋 객체 생성\n",
        "train_dataset = LabeledNumpyArrayDataset(X_train, y_train)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_dataset = LabeledNumpyArrayDataset(X_test, y_test)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TMAHztyso_m"
      },
      "source": [
        "### 모델 학습 (Vanilla RNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "PaX9qNpYljQi"
      },
      "outputs": [],
      "source": [
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, layer_dim, output_dim, dropout_prob, device):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.device = device\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.layer_dim = layer_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        self.rnn = nn.RNN(\n",
        "            embedding_dim, hidden_dim, layer_dim, batch_first=True, dropout=dropout_prob\n",
        "        )\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(embedding_dim, output_dim)\n",
        "\n",
        "    def forward(self, text):\n",
        "        embedded = self.embedding(text)\n",
        "\n",
        "        h0 = torch.zeros(self.layer_dim, text.size(0), self.hidden_dim).requires_grad_()\n",
        "        h0 = h0.to(self.device)\n",
        "        out, h0 = self.rnn(embedded, h0.detach())\n",
        "\n",
        "        # 현재 out의 차원은 (batch_size, seq_length, hidden_size)입니다.\n",
        "        # 이를 fully connected layer에 fit하게 차원을 변경(batch_size, hidden_size)해주어야 합니다.\n",
        "        out = out[:, -1, :] # 64 x 64 size\n",
        "\n",
        "        \"\"\"\n",
        "        문제 1: 이제 out을 우리가 원하는 ouput_dim 차원으로 변환해주어야 합니다.\n",
        "        빈칸에 들어갈 인스턴스 변수를 채워넣어주세요.\n",
        "        \"\"\"\n",
        "        # out = self.\"빈칸\"(out)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "yLCP04LFvZlD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7811206f-0bfc-4494-b58b-679bb9bab125"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "num_epoch = 15\n",
        "batch_size = 64\n",
        "embedding_dim = 64\n",
        "hidden_dim = 64\n",
        "layer_dim = 1\n",
        "output_dim = 4\n",
        "\n",
        "model = RNNModel(vocab_size, embedding_dim, hidden_dim, layer_dim, output_dim, 0.5, device)\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr= 0.005)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "문제 2: RNN에서 loss를 계산하는 기준은 무엇일까요? 빈칸에 알맞은 답을 적어주세요\n",
        "\"\"\"\n",
        "# criterion = nn.\"빈칸\"()\n",
        "# RNN에서 loss를 계산하는 기준은 예측 값과 실제 값 사이의 차이를 측정하는 것\n",
        "# output_dim이 4이므로, 크로스 엔트로피 손실 함수 (CrossEntropyLoss)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFQCXBDf17hW",
        "outputId": "cca817c1-5f6b-4509-f703-9b379efc6349"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 500. Loss: 0.4677005112171173. Accuracy: 86.53394317626953\n",
            "Iteration: 1000. Loss: 0.4250046908855438. Accuracy: 85.99369812011719\n",
            "Iteration: 1500. Loss: 0.4271482527256012. Accuracy: 84.14036560058594\n",
            "Iteration: 2000. Loss: 0.3445174992084503. Accuracy: 87.66695404052734\n",
            "Iteration: 2500. Loss: 0.30116406083106995. Accuracy: 87.50437927246094\n",
            "Iteration: 3000. Loss: 0.38100534677505493. Accuracy: 88.43229675292969\n",
            "Iteration: 3500. Loss: 0.21219995617866516. Accuracy: 89.07258605957031\n",
            "Iteration: 4000. Loss: 0.3833254873752594. Accuracy: 86.4263916015625\n",
            "Iteration: 4500. Loss: 0.2685765326023102. Accuracy: 85.613525390625\n",
            "Iteration: 5000. Loss: 0.27238839864730835. Accuracy: 87.5919189453125\n",
            "Iteration: 5500. Loss: 0.2868868112564087. Accuracy: 86.56145477294922\n",
            "Iteration: 6000. Loss: 0.14117494225502014. Accuracy: 85.8886489868164\n",
            "Iteration: 6500. Loss: 0.21528629958629608. Accuracy: 87.88204956054688\n",
            "Iteration: 7000. Loss: 0.3326454758644104. Accuracy: 88.3272476196289\n",
            "Iteration: 7500. Loss: 0.15043534338474274. Accuracy: 88.02461242675781\n",
            "Iteration: 8000. Loss: 0.2883997857570648. Accuracy: 87.8995590209961\n",
            "Iteration: 8500. Loss: 0.3357725143432617. Accuracy: 87.72947692871094\n",
            "Iteration: 9000. Loss: 0.35997411608695984. Accuracy: 86.656494140625\n",
            "Iteration: 9500. Loss: 0.39450904726982117. Accuracy: 87.24176025390625\n",
            "Iteration: 10000. Loss: 0.2478821575641632. Accuracy: 87.36931610107422\n",
            "Iteration: 10500. Loss: 0.3057054877281189. Accuracy: 86.99414825439453\n",
            "Iteration: 11000. Loss: 0.3230082094669342. Accuracy: 85.8986587524414\n",
            "Iteration: 11500. Loss: 0.21513046324253082. Accuracy: 87.0541763305664\n",
            "Iteration: 12000. Loss: 0.2613409161567688. Accuracy: 87.40433502197266\n",
            "Iteration: 12500. Loss: 0.22846904397010803. Accuracy: 87.48436737060547\n",
            "Iteration: 13000. Loss: 0.2994750142097473. Accuracy: 87.7494888305664\n",
            "Iteration: 13500. Loss: 0.41895025968551636. Accuracy: 87.40933227539062\n",
            "Iteration: 14000. Loss: 0.215155690908432. Accuracy: 88.12215423583984\n",
            "Iteration: 14500. Loss: 0.2595973610877991. Accuracy: 88.14716339111328\n",
            "Iteration: 15000. Loss: 0.18646091222763062. Accuracy: 88.19969177246094\n",
            "Iteration: 15500. Loss: 0.3963809013366699. Accuracy: 88.34725952148438\n",
            "Iteration: 16000. Loss: 0.26199930906295776. Accuracy: 88.29973602294922\n",
            "Iteration: 16500. Loss: 0.19632910192012787. Accuracy: 88.16217041015625\n",
            "Iteration: 17000. Loss: 0.30136391520500183. Accuracy: 88.31974792480469\n",
            "Iteration: 17500. Loss: 0.3303823173046112. Accuracy: 87.47186279296875\n",
            "Iteration: 18000. Loss: 0.140410915017128. Accuracy: 88.63988494873047\n",
            "Iteration: 18500. Loss: 0.22902391850948334. Accuracy: 88.59986877441406\n",
            "Iteration: 19000. Loss: 0.2803087532520294. Accuracy: 88.11215209960938\n",
            "Iteration: 19500. Loss: 0.29175493121147156. Accuracy: 88.6749038696289\n",
            "Iteration: 20000. Loss: 0.2828795909881592. Accuracy: 87.38432312011719\n",
            "Iteration: 20500. Loss: 0.15831823647022247. Accuracy: 87.69446563720703\n",
            "Iteration: 21000. Loss: 0.2330300658941269. Accuracy: 88.11215209960938\n",
            "Iteration: 21500. Loss: 0.207894966006279. Accuracy: 87.7544937133789\n",
            "Iteration: 22000. Loss: 0.37623897194862366. Accuracy: 88.047119140625\n",
            "Iteration: 22500. Loss: 0.14949439465999603. Accuracy: 88.0521240234375\n",
            "Iteration: 23000. Loss: 0.3303397297859192. Accuracy: 85.6185302734375\n",
            "Iteration: 23500. Loss: 0.33391624689102173. Accuracy: 86.6614990234375\n",
            "Iteration: 24000. Loss: 0.32309138774871826. Accuracy: 87.81951904296875\n",
            "Iteration: 24500. Loss: 0.29824185371398926. Accuracy: 88.22470092773438\n",
            "Iteration: 25000. Loss: 0.21356458961963654. Accuracy: 88.21720123291016\n",
            "Iteration: 25500. Loss: 0.24163365364074707. Accuracy: 87.67695617675781\n",
            "Iteration: 26000. Loss: 0.24450279772281647. Accuracy: 87.4693603515625\n",
            "Iteration: 26500. Loss: 0.3673752546310425. Accuracy: 87.42183685302734\n",
            "Iteration: 27000. Loss: 0.40494170784950256. Accuracy: 87.33679962158203\n",
            "Iteration: 27500. Loss: 0.31977248191833496. Accuracy: 87.57941436767578\n",
            "Iteration: 28000. Loss: 0.4051077663898468. Accuracy: 87.90956115722656\n",
            "Iteration: 28500. Loss: 0.2677136957645416. Accuracy: 87.92456817626953\n",
            "Iteration: 29000. Loss: 0.4496515393257141. Accuracy: 87.89205169677734\n",
            "Iteration: 29500. Loss: 0.3009837567806244. Accuracy: 88.12215423583984\n",
            "Iteration: 30000. Loss: 0.26305511593818665. Accuracy: 85.86614227294922\n",
            "Iteration: 30500. Loss: 0.33675456047058105. Accuracy: 84.43799591064453\n",
            "Iteration: 31000. Loss: 0.2960010766983032. Accuracy: 84.8106689453125\n",
            "Iteration: 31500. Loss: 0.3757253587245941. Accuracy: 85.26087188720703\n",
            "Iteration: 32000. Loss: 0.27541810274124146. Accuracy: 85.28588104248047\n",
            "Iteration: 32500. Loss: 0.1585218906402588. Accuracy: 86.92662048339844\n",
            "Iteration: 33000. Loss: 0.14665259420871735. Accuracy: 87.19173431396484\n",
            "Iteration: 33500. Loss: 0.2704695463180542. Accuracy: 87.61442565917969\n",
            "Iteration: 34000. Loss: 0.2994927763938904. Accuracy: 87.15171813964844\n",
            "Iteration: 34500. Loss: 0.16031716763973236. Accuracy: 87.09669494628906\n",
            "Iteration: 35000. Loss: 0.1767338216304779. Accuracy: 87.61692810058594\n",
            "Iteration: 35500. Loss: 0.22272014617919922. Accuracy: 87.2792739868164\n",
            "Iteration: 36000. Loss: 0.2893725335597992. Accuracy: 87.26426696777344\n",
            "Iteration: 36500. Loss: 0.24006378650665283. Accuracy: 87.30429077148438\n",
            "Iteration: 37000. Loss: 0.28582578897476196. Accuracy: 87.56440734863281\n"
          ]
        }
      ],
      "source": [
        "iter = 0\n",
        "for epoch in range(num_epoch):\n",
        "    for i, (text, labels) in enumerate(train_dataloader):\n",
        "        model.train()\n",
        "\n",
        "        text = text.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        logits = model(text).to(device)\n",
        "\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "        문제2: loss를 구하기 위해서 위에서 정의한 변수 중 무엇을 사용하면 될까요? 빈칸을 채워넣어주세요.\n",
        "        \"\"\"\n",
        "        # loss = \"빈칸\"(logits, labels)\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        \"\"\"\n",
        "        문제3: 역전파를 거친 후 매개변수(가중치)를 업데이트하기 위해서 필요한 메서드는 무엇이었나요?\n",
        "        빈칸을 채워넣어주세요.\n",
        "        \"\"\"\n",
        "        # \"빈칸\"()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "        if iter % 500 == 0:\n",
        "            model.eval()\n",
        "            # Calculate Accuracy\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            for test_text, test_labels in test_dataloader:\n",
        "                test_text = test_text.to(device)\n",
        "                test_labels = test_labels.to(device)\n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(test_text)\n",
        "\n",
        "                # Get predictions from the maximum value\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "                # Total number of labels\n",
        "                total += test_labels.size(0)\n",
        "\n",
        "                # Total correct predictions\n",
        "                correct += (predicted == test_labels).sum()\n",
        "\n",
        "            accuracy = 100 * correct / total\n",
        "\n",
        "            # Print Loss\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7C3Q3Cd3lkYw"
      },
      "source": [
        "### 모델학습 (LSTM, Long short term memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "5j23sTsP2Sv_"
      },
      "outputs": [],
      "source": [
        "class LSTMModel(nn.Module):\n",
        "\n",
        "    def __init__(self,vocab_size, embedding_dim, hidden_dim, layer_dim, output_dim, dropout_prob, device):\n",
        "        super(LSTMModel, self).__init__()\n",
        "\n",
        "        self.device = device\n",
        "\n",
        "        # Defining the number of layers and the nodes in each layer\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.layer_dim = layer_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # LSTM layers\n",
        "        self.lstm = nn.LSTM(\n",
        "            embedding_dim, hidden_dim, layer_dim, batch_first=True, dropout=dropout_prob\n",
        "        )\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(embedding_dim, output_dim)\n",
        "\n",
        "    def forward(self, text):\n",
        "        embedded = self.embedding(text)\n",
        "\n",
        "        h0 = torch.zeros(self.layer_dim, text.size(0), self.hidden_dim).requires_grad_()\n",
        "        h0 = h0.to(self.device)\n",
        "\n",
        "        # 초기에 cell state를 영행렬로 초기화\n",
        "        c0 = torch.zeros(self.layer_dim, text.size(0), self.hidden_dim).requires_grad_()\n",
        "        c0 = c0.to(self.device)\n",
        "\n",
        "        out, (hn, cn) = self.lstm(embedded, (h0.detach(), c0.detach()))\n",
        "\n",
        "        # 현재 out의 차원은 (batch_size, seq_length, hidden_size)입니다.\n",
        "        # 이를 fully connected layer에 fit하게 차원을 변경(batch_size, hidden_size)해주어야 합니다.\n",
        "        out = out[:, -1, :]\n",
        "\n",
        "        # fc layer를 통해 (batch_size, output_dim)로 차원을 변경해줍니다.\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Q-PZquMSZ6Fp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34e09fbb-dd77-4dc0-fa14-46f1a11302a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "num_epoch = 15\n",
        "batch_size = 64\n",
        "embedding_dim = 64\n",
        "hidden_dim = 64\n",
        "layer_dim = 1\n",
        "output_dim = 4\n",
        "\n",
        "model = LSTMModel(vocab_size, embedding_dim, hidden_dim, layer_dim, output_dim, 0.5, device)\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr= 0.005)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvcL3dQVYDx5",
        "outputId": "dfed128e-d5eb-45d7-a3f9-5744b91bd6ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 1000. Loss: 0.2218695729970932. Accuracy: 90.80586242675781\n",
            "Iteration: 2000. Loss: 0.09058994799852371. Accuracy: 91.34110260009766\n",
            "Iteration: 3000. Loss: 0.17532165348529816. Accuracy: 91.7637939453125\n",
            "Iteration: 4000. Loss: 0.2731926739215851. Accuracy: 91.86133575439453\n",
            "Iteration: 5000. Loss: 0.08464805036783218. Accuracy: 91.93637084960938\n",
            "Iteration: 6000. Loss: 0.174563467502594. Accuracy: 91.27607727050781\n",
            "Iteration: 7000. Loss: 0.14326179027557373. Accuracy: 91.53369140625\n",
            "Iteration: 8000. Loss: 0.2163500040769577. Accuracy: 91.71627044677734\n",
            "Iteration: 9000. Loss: 0.20583471655845642. Accuracy: 91.44865417480469\n",
            "Iteration: 10000. Loss: 0.05040454864501953. Accuracy: 91.6912612915039\n",
            "Iteration: 11000. Loss: 0.07327397912740707. Accuracy: 91.3386001586914\n",
            "Iteration: 12000. Loss: 0.05505824089050293. Accuracy: 91.28357696533203\n",
            "Iteration: 13000. Loss: 0.049038227647542953. Accuracy: 91.0634765625\n",
            "Iteration: 14000. Loss: 0.09151293337345123. Accuracy: 91.04597473144531\n",
            "Iteration: 15000. Loss: 0.14065392315387726. Accuracy: 90.95843505859375\n",
            "Iteration: 16000. Loss: 0.16253402829170227. Accuracy: 90.80335998535156\n",
            "Iteration: 17000. Loss: 0.10735790431499481. Accuracy: 90.82086944580078\n",
            "Iteration: 18000. Loss: 0.09537556022405624. Accuracy: 90.61327362060547\n",
            "Iteration: 19000. Loss: 0.30148640275001526. Accuracy: 90.39567565917969\n",
            "Iteration: 20000. Loss: 0.0433487631380558. Accuracy: 90.39817810058594\n",
            "Iteration: 21000. Loss: 0.020575426518917084. Accuracy: 90.35066223144531\n",
            "Iteration: 22000. Loss: 0.1517595648765564. Accuracy: 90.378173828125\n",
            "Iteration: 23000. Loss: 0.049046773463487625. Accuracy: 90.36066436767578\n",
            "Iteration: 24000. Loss: 0.07096726447343826. Accuracy: 90.25811767578125\n",
            "Iteration: 25000. Loss: 0.050232723355293274. Accuracy: 90.5357437133789\n",
            "Iteration: 26000. Loss: 0.014848845079541206. Accuracy: 90.13056182861328\n",
            "Iteration: 27000. Loss: 0.15293191373348236. Accuracy: 90.29312896728516\n",
            "Iteration: 28000. Loss: 0.13060757517814636. Accuracy: 90.38066864013672\n",
            "Iteration: 29000. Loss: 0.18374714255332947. Accuracy: 90.255615234375\n",
            "Iteration: 30000. Loss: 0.09557405859231949. Accuracy: 89.89545440673828\n",
            "Iteration: 31000. Loss: 0.13426826894283295. Accuracy: 89.82542419433594\n",
            "Iteration: 32000. Loss: 0.045929234474897385. Accuracy: 90.14056396484375\n",
            "Iteration: 33000. Loss: 0.03788352012634277. Accuracy: 90.23560333251953\n",
            "Iteration: 34000. Loss: 0.05014928802847862. Accuracy: 90.19308471679688\n",
            "Iteration: 35000. Loss: 0.010195483453571796. Accuracy: 90.18058013916016\n",
            "Iteration: 36000. Loss: 0.06205647438764572. Accuracy: 90.01300811767578\n",
            "Iteration: 37000. Loss: 0.08989662677049637. Accuracy: 89.84542846679688\n"
          ]
        }
      ],
      "source": [
        "iter = 0\n",
        "for epoch in range(num_epoch):\n",
        "    for i, (text, labels) in enumerate(train_dataloader):\n",
        "        model.train()\n",
        "\n",
        "        text = text.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        logits = model(text).to(device)\n",
        "\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "        if iter % 1000 == 0:\n",
        "            model.eval()\n",
        "            # Calculate Accuracy\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            for test_text, test_labels in test_dataloader:\n",
        "                test_text = test_text.to(device)\n",
        "                test_labels = test_labels.to(device)\n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(test_text)\n",
        "\n",
        "                # Get predictions from the maximum value\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "                # Total number of labels\n",
        "                total += test_labels.size(0)\n",
        "\n",
        "                # Total correct predictions\n",
        "                correct += (predicted == test_labels).sum()\n",
        "\n",
        "            accuracy = 100 * correct / total\n",
        "\n",
        "            # Print Loss\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEmWGtFslpiz"
      },
      "source": [
        "### 모델 학습 (Gated Recurrent Unit (GRU))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "zpaGyyY2ltWF"
      },
      "outputs": [],
      "source": [
        "class GRUModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, layer_dim, output_dim, dropout_prob, device):\n",
        "        super(GRUModel, self).__init__()\n",
        "\n",
        "        # Defining the number of layers and the nodes in each layer\n",
        "        self.device = device\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.layer_dim = layer_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # GRU layers\n",
        "        self.gru = nn.GRU(\n",
        "            embedding_dim, hidden_dim, layer_dim, batch_first=True, dropout=dropout_prob\n",
        "        )\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(embedding_dim, output_dim)\n",
        "\n",
        "    def forward(self, text):\n",
        "\n",
        "        embedded = self.embedding(text)\n",
        "\n",
        "        # Initializing hidden state for first input with zeros\n",
        "        h0 = torch.zeros(self.layer_dim, text.size(0), self.hidden_dim).requires_grad_()\n",
        "        h0 = h0.to(self.device)\n",
        "\n",
        "        # Forward propagation by passing in the input and hidden state into the model\n",
        "        out, _ = self.gru(embedded, h0.detach())\n",
        "\n",
        "        # Reshaping the outputs in the shape of (batch_size, seq_length, hidden_size)\n",
        "        # so that it can fit into the fully connected layer\n",
        "        out = out[:, -1, :]\n",
        "\n",
        "        # Convert the final state to our desired output shape (batch_size, output_dim)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "q59GPyZSaZjX"
      },
      "outputs": [],
      "source": [
        "num_epoch = 15\n",
        "batch_size = 64\n",
        "embedding_dim = 64\n",
        "hidden_dim = 64\n",
        "layer_dim = 1\n",
        "output_dim = 4\n",
        "\n",
        "model = GRUModel(vocab_size, embedding_dim, hidden_dim, layer_dim, output_dim, 0.5, device)\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr= 0.005)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLd0utoBacFW",
        "outputId": "95e1e3e8-861c-469b-ec9c-769fa3a50615"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 1000. Loss: 0.19015565514564514. Accuracy: 90.9559326171875\n",
            "Iteration: 2000. Loss: 0.4209724962711334. Accuracy: 91.57621002197266\n",
            "Iteration: 3000. Loss: 0.38225507736206055. Accuracy: 91.32109832763672\n",
            "Iteration: 4000. Loss: 0.13393600285053253. Accuracy: 91.51367950439453\n",
            "Iteration: 5000. Loss: 0.1505785882472992. Accuracy: 91.71627044677734\n",
            "Iteration: 6000. Loss: 0.15644508600234985. Accuracy: 91.38362121582031\n",
            "Iteration: 7000. Loss: 0.1858905404806137. Accuracy: 91.48117065429688\n",
            "Iteration: 8000. Loss: 0.14644555747509003. Accuracy: 91.39862823486328\n",
            "Iteration: 9000. Loss: 0.1890096217393875. Accuracy: 91.0009536743164\n",
            "Iteration: 10000. Loss: 0.06273431330919266. Accuracy: 91.16602325439453\n",
            "Iteration: 11000. Loss: 0.10101236402988434. Accuracy: 91.1810302734375\n",
            "Iteration: 12000. Loss: 0.07012052834033966. Accuracy: 90.96092987060547\n",
            "Iteration: 13000. Loss: 0.24600781500339508. Accuracy: 90.94842529296875\n",
            "Iteration: 14000. Loss: 0.1478634774684906. Accuracy: 90.87589263916016\n",
            "Iteration: 15000. Loss: 0.10746558755636215. Accuracy: 90.77584838867188\n",
            "Iteration: 16000. Loss: 0.11091721802949905. Accuracy: 90.70832061767578\n",
            "Iteration: 17000. Loss: 0.08921942114830017. Accuracy: 90.62328338623047\n",
            "Iteration: 18000. Loss: 0.09519323706626892. Accuracy: 90.60577392578125\n",
            "Iteration: 19000. Loss: 0.10463757067918777. Accuracy: 90.603271484375\n",
            "Iteration: 20000. Loss: 0.154660165309906. Accuracy: 90.43819427490234\n",
            "Iteration: 21000. Loss: 0.09346596151590347. Accuracy: 90.2506103515625\n",
            "Iteration: 22000. Loss: 0.06831119954586029. Accuracy: 90.3681640625\n",
            "Iteration: 23000. Loss: 0.14964154362678528. Accuracy: 90.55574798583984\n",
            "Iteration: 24000. Loss: 0.07306893914937973. Accuracy: 90.1780776977539\n",
            "Iteration: 25000. Loss: 0.15154048800468445. Accuracy: 90.36316680908203\n",
            "Iteration: 26000. Loss: 0.2102062851190567. Accuracy: 90.00800323486328\n",
            "Iteration: 27000. Loss: 0.028155187144875526. Accuracy: 90.18058013916016\n",
            "Iteration: 28000. Loss: 0.1695902943611145. Accuracy: 90.34315490722656\n",
            "Iteration: 29000. Loss: 0.05002699792385101. Accuracy: 90.24561309814453\n",
            "Iteration: 30000. Loss: 0.08378634601831436. Accuracy: 90.2506103515625\n",
            "Iteration: 31000. Loss: 0.09943253546953201. Accuracy: 90.11805725097656\n",
            "Iteration: 32000. Loss: 0.10620945692062378. Accuracy: 89.9129638671875\n",
            "Iteration: 33000. Loss: 0.06479477882385254. Accuracy: 90.05802917480469\n",
            "Iteration: 34000. Loss: 0.13222643733024597. Accuracy: 89.93296813964844\n",
            "Iteration: 35000. Loss: 0.1273636668920517. Accuracy: 90.378173828125\n",
            "Iteration: 36000. Loss: 0.10992718487977982. Accuracy: 90.06053161621094\n",
            "Iteration: 37000. Loss: 0.18207712471485138. Accuracy: 90.07553100585938\n"
          ]
        }
      ],
      "source": [
        "iter = 0\n",
        "for epoch in range(num_epoch):\n",
        "    for i, (text, labels) in enumerate(train_dataloader):\n",
        "        model.train()\n",
        "\n",
        "        text = text.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        logits = model(text).to(device)\n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "        if iter % 1000 == 0:\n",
        "            model.eval()\n",
        "            # Calculate Accuracy\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            for test_text, test_labels in test_dataloader:\n",
        "                test_text = test_text.to(device)\n",
        "                test_labels = test_labels.to(device)\n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(test_text)\n",
        "\n",
        "                # Get predictions from the maximum value\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "                # Total number of labels\n",
        "                total += test_labels.size(0)\n",
        "\n",
        "                # Total correct predictions\n",
        "                correct += (predicted == test_labels).sum()\n",
        "\n",
        "            accuracy = 100 * correct / total\n",
        "\n",
        "            # Print Loss\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjuXGLI7eA2X"
      },
      "source": [
        "## 모델 성능 비교"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cH2yfHfheC-l"
      },
      "source": [
        "옵티마이저, 파라미터 등을 바꿔가며 모델의 성능을 향상시켜보세요.\n",
        "\n",
        "이후 세 가지 모델의 성능 차이를 비교하고, 자유롭게 해석해보세요!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "lstm과 gru의 성능은 비슷, 걸린 시간도 2분 정도로 큰 차이가 없다.\n",
        "\n",
        "Vanilla RNN도 걸린 시간은 비슷하지만, 이전 모델들에 비해 다소 낮은 성능을 보임."
      ],
      "metadata": {
        "id": "Ncp3K6gOSXoJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "궁금한 점: output_dim=4인 것\n",
        "\n",
        "label이 0,1만 존재하므로, 모델은 뒤의 2개의 불필요한 출력을 무시하고 0,1에만 초점을 맞춤. -> 즉, logits[:, 0]과 logits[:, 1]이 중요한 값이 됨.\n",
        "\n",
        "<br>\n",
        "\n",
        "labels 값이 0이면, logits[:, 0]을 높이고\n",
        "\n",
        "labels 값이 1이면, logits[:, 1]을 높이도록 학습\n",
        "\n",
        "즉, 출력 벡터 [batch_size, 4] 중 index 0과 1만 의미를 가짐\n",
        "\n",
        "나머지 index 2~3는 학습에 기여하지 않음 → 비효율적!"
      ],
      "metadata": {
        "id": "gXDC7YL3XKxA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGWK-6sVStHG"
      },
      "source": [
        "### 모델 학습 (Gated Recurrent Unit (GRU))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "auDjORQtStHH"
      },
      "outputs": [],
      "source": [
        "class GRUModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, layer_dim, output_dim, dropout_prob, device):\n",
        "        super(GRUModel, self).__init__()\n",
        "\n",
        "        # Defining the number of layers and the nodes in each layer\n",
        "        self.device = device\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.layer_dim = layer_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # GRU layers\n",
        "        self.gru = nn.GRU(\n",
        "            embedding_dim, hidden_dim, layer_dim, batch_first=True, dropout=dropout_prob\n",
        "        )\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(embedding_dim, output_dim)\n",
        "\n",
        "    def forward(self, text):\n",
        "\n",
        "        embedded = self.embedding(text)\n",
        "\n",
        "        # Initializing hidden state for first input with zeros\n",
        "        h0 = torch.zeros(self.layer_dim, text.size(0), self.hidden_dim).requires_grad_()\n",
        "        h0 = h0.to(self.device)\n",
        "\n",
        "        # Forward propagation by passing in the input and hidden state into the model\n",
        "        out, _ = self.gru(embedded, h0.detach())\n",
        "\n",
        "        # Reshaping the outputs in the shape of (batch_size, seq_length, hidden_size)\n",
        "        # so that it can fit into the fully connected layer\n",
        "        out = out[:, -1, :]\n",
        "\n",
        "        # Convert the final state to our desired output shape (batch_size, output_dim)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "imbFeimjStHH"
      },
      "outputs": [],
      "source": [
        "num_epoch = 5\n",
        "batch_size = 64\n",
        "embedding_dim = 64\n",
        "hidden_dim = 64\n",
        "layer_dim = 1\n",
        "output_dim = 2\n",
        "\n",
        "model = GRUModel(vocab_size, embedding_dim, hidden_dim, layer_dim, output_dim, 0.5, device)\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr= 0.003)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e96b32f-1c46-4549-dc0f-281db90f53ba",
        "id": "rrgVBxJaStHH"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 1000. Loss: 0.16760699450969696. Accuracy: 90.6432876586914\n",
            "Iteration: 2000. Loss: 0.2591794431209564. Accuracy: 91.34610748291016\n",
            "Iteration: 3000. Loss: 0.190218985080719. Accuracy: 91.7187728881836\n",
            "Iteration: 4000. Loss: 0.17987477779388428. Accuracy: 91.61622619628906\n",
            "Iteration: 5000. Loss: 0.06464774906635284. Accuracy: 91.94387817382812\n",
            "Iteration: 6000. Loss: 0.23970560729503632. Accuracy: 91.54119110107422\n",
            "Iteration: 7000. Loss: 0.1988898515701294. Accuracy: 91.73377990722656\n",
            "Iteration: 8000. Loss: 0.0959366112947464. Accuracy: 91.32359313964844\n",
            "Iteration: 9000. Loss: 0.058013997972011566. Accuracy: 91.53118896484375\n",
            "Iteration: 10000. Loss: 0.08380930870771408. Accuracy: 91.49117279052734\n",
            "Iteration: 11000. Loss: 0.053840335458517075. Accuracy: 91.42864227294922\n",
            "Iteration: 12000. Loss: 0.15933164954185486. Accuracy: 91.30609130859375\n"
          ]
        }
      ],
      "source": [
        "iter = 0\n",
        "for epoch in range(num_epoch):\n",
        "    for i, (text, labels) in enumerate(train_dataloader):\n",
        "        model.train()\n",
        "\n",
        "        text = text.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        logits = model(text).to(device)\n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "        if iter % 1000 == 0:\n",
        "            model.eval()\n",
        "            # Calculate Accuracy\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            for test_text, test_labels in test_dataloader:\n",
        "                test_text = test_text.to(device)\n",
        "                test_labels = test_labels.to(device)\n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(test_text)\n",
        "\n",
        "                # Get predictions from the maximum value\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "                # Total number of labels\n",
        "                total += test_labels.size(0)\n",
        "\n",
        "                # Total correct predictions\n",
        "                correct += (predicted == test_labels).sum()\n",
        "\n",
        "            accuracy = 100 * correct / total\n",
        "\n",
        "            # Print Loss\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hmZQtuKgWNJZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}