import os
import sys
import glob
import torch
import nibabel as nib
import numpy as np
import argparse
import pandas as pd
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from transformers import CLIPProcessor, CLIPModel
from tqdm import tqdm
import random

# ëžœë¤ ì‹œë“œ ì„¤ì •
def set_random_seed(seed=1):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

set_random_seed(1)  # ì‹¤í–‰ ì‹œ í•­ìƒ ê°™ì€ ê²°ê³¼ ë³´ìž¥

# GPU ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# MRI ë°ì´í„° í´ë” ë° CSV íŒŒì¼ ê²½ë¡œ
mri_folder = "./nifti/"
csv_path = "./oasis_cross_sectional.csv"

# CSV íŒŒì¼ ë¡œë“œ
df = pd.read_csv(csv_path)

# MRI íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
mri_files = glob.glob(os.path.join(mri_folder, "**/*.nii"))
print(f"ì´ {len(mri_files)}ê°œì˜ MRI íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

# CSV íŒŒì¼ ID ì •ë¦¬
def extract_id_from_filename(filename):
    return os.path.basename(filename).split('_')[1]

def extract_id_from_csv(original_id):
    return original_id.split('_')[1]

df['ID'] = df['ID'].apply(extract_id_from_csv)

# MRI íŒŒì¼ê³¼ CSV ë§¤ì¹­
matched_data = []
for filename in mri_files:
    mri_id = extract_id_from_filename(filename)
    row = df[df['ID'] == mri_id]
    if not row.empty:
        # CSVì—ì„œ CLIP_Text ì „ì²´ë¥¼ ì½ì–´ì˜¨ ë‹¤ìŒ
        full_text = row.iloc[0]["CLIP_Text"]

        # ì—¬ê¸°ì„œ ì›í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ í•„ìš”í•œ ë¶€ë¶„ë§Œ ì¶”ì¶œ
        # ì˜ˆì‹œ) "This is an MRI scan of a 74-year-old female" ê¹Œì§€ ìž˜ë¼ë‚´ëŠ” ê°„ë‹¨í•œ ë°©ë²•

        # 1) ë‹¨ìˆœížˆ í‚¤ì›Œë“œë¡œ ìž˜ë¼ë‚´ëŠ” ê²½ìš°
        # íŠ¹ì • êµ¬ë¬¸ ì§í›„ë¡œë§Œ ìž˜ë¼ë‚´ê³  ì‹¶ë‹¤ë©´ (í‚¤ì›Œë“œ ì´í›„ ë¬¸ìž¥ ì œê±° ë“±)
        keyword = "male"
        # ë§Œì•½ CSV ë‚´ìš© ì¤‘ì— í•´ë‹¹ keywordê°€ ìžˆë‹¤ë©´ ê·¸ ë¶€ë¶„ê¹Œì§€ë§Œ ì¶”ì¶œ
        if keyword in full_text:
            idx = full_text.index(keyword) + len(keyword)
            clip_text = full_text[:idx]
        else:
            # keywordê°€ ì—†ëŠ” ê²½ìš°, ê¸°ë³¸ì ìœ¼ë¡œ full_textë¥¼ ê·¸ëŒ€ë¡œ ì“°ê±°ë‚˜, ë¹ˆ ë¬¸ìžì—´ ì²˜ë¦¬
            clip_text = full_text
        #print(clip_text)

        # 2) ë¬¸ìž¥ ë‹¨ìœ„ë¡œ ìž˜ë¼ë‚´ëŠ” ê²½ìš°
        # ì–´ë–¤ ë¬¸ìž¥ë¶€í˜¸(.) ê¸°ì¤€ìœ¼ë¡œ ìžë¥´ê³  ì²« ë¬¸ìž¥ë§Œ ì“°ê³  ì‹¶ë‹¤ë©´ ì˜ˆì‹œ:
        # sentences = full_text.split('.')
        # clip_text = sentences[0] + '.' if len(sentences) > 0 else ''

        # ì´í›„ matched_dataì— ì €ìž¥
        matched_data.append({
            "mri_path": filename,
            "clip_text": clip_text,
            "label": row.iloc[0]["CDR"]
        })

print(f"ì´ {len(matched_data)}ê°œì˜ MRI ë°ì´í„°ê°€ CSVì™€ ë§¤ì¹­ë˜ì—ˆìŠµë‹ˆë‹¤.")

# ë°ì´í„°ì…‹ í´ëž˜ìŠ¤ ì •ì˜
class OASISDataset(Dataset):
    def __init__(self, matched_data):
        self.data = matched_data

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        sample = self.data[idx]
        nii_img = nib.load(sample['mri_path'])
        img_data = nii_img.get_fdata()

        # MRI ë°ì´í„° ë³€í™˜
        if len(img_data.shape) == 3:
            img_data = np.expand_dims(img_data, axis=0)
        elif len(img_data.shape) == 4 and img_data.shape[-1] == 1:
            img_data = img_data[..., 0]
            img_data = np.expand_dims(img_data, axis=0)
        else:
            raise ValueError(f"âŒ MRI ë°ì´í„° ì°¨ì›ì´ ì˜ˆìƒê³¼ ë‹¤ë¦„: {img_data.shape}")

        # ì •ê·œí™”
        img_data = (img_data - np.min(img_data)) / (np.max(img_data) - np.min(img_data))
        img_data = torch.tensor(img_data, dtype=torch.float32).unsqueeze(0)
        img_data = F.interpolate(img_data, size=(16, 112, 112), mode='trilinear', align_corners=False)
        img_data = img_data.squeeze(0)

        return img_data, sample['clip_text'], torch.tensor(sample['label'], dtype=torch.long)

# ë°ì´í„° ë¶„í• 
def split_data(matched_data, seed=1):
    set_random_seed(seed)
    random.shuffle(matched_data)
    train_size = int(0.8 * len(matched_data))
    val_size = int(0.1 * len(matched_data))
    test_size = len(matched_data) - train_size - val_size

    return (
        OASISDataset(matched_data[:train_size]),
        OASISDataset(matched_data[train_size:train_size+val_size]),
        OASISDataset(matched_data[train_size+val_size:])
    )

# MedicalNet MRI ì¸ì½”ë”
sys.path.append("./MedicalNet")
from MedicalNet.model import generate_model

class MedicalNetEncoder(nn.Module):
    def __init__(self, feature_dim=512, use_pretrained=False):
        super(MedicalNetEncoder, self).__init__()
        opt = argparse.Namespace(
            model='resnet', model_depth=10, input_W=112, input_H=112, input_D=16,
            resnet_shortcut='B', no_cuda=False, n_seg_classes=2, gpu_id=[0],
            phase='train', pretrain_path="./MedicalNet/resnet_10.pth" if use_pretrained else None,
            new_layer_names=[]
        )
        self.model, _ = generate_model(opt)
        self.model.fc = nn.Identity()
        self.model.to(device)

    def forward(self, x):
        return self.model(x)

class TextEncoder(nn.Module):
    def __init__(self, model_name="openai/clip-vit-base-patch32"):
        super(TextEncoder, self).__init__()
        self.device = device
        self.model = CLIPModel.from_pretrained(model_name).to(device)
        self.processor = CLIPProcessor.from_pretrained(model_name)

    def forward(self, text):
        if isinstance(text, list):
            text = text[0]  # CLIP_Textê°€ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë“¤ì–´ì˜¤ëŠ” ê²½ìš° ëŒ€ë¹„
        inputs = self.processor(text=text, return_tensors="pt", padding=True, truncation=True).to(self.device)
        text_features = self.model.get_text_features(**inputs)
        return text_features

# ë©€í‹°ëª¨ë‹¬ ë¶„ë¥˜ ëª¨ë¸ ì •ì˜
class MultimodalClassifier(nn.Module):
    def __init__(self, feature_dim=512, num_classes=4):
        super(MultimodalClassifier, self).__init__()
        # 6272ëŠ” mri_encoderì˜ ì¶œë ¥ shapeì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìžˆìŒ
        self.mri_fc = nn.Linear(6272, feature_dim)
        self.text_fc = nn.Linear(512, feature_dim)
        self.relu = nn.ReLU()
        self.fusion_layer = nn.Linear(feature_dim * 2, feature_dim)
        self.classifier = nn.Sequential(
            nn.Linear(feature_dim, 256),
            nn.ReLU(),
            nn.Linear(256, 64),
            nn.ReLU(),
            nn.Linear(64, num_classes)
        )

    def forward(self, mri_features, text_features):
        mri_features = mri_features.view(mri_features.size(0), -1)
        mri_features = self.mri_fc(mri_features)
        text_features = self.text_fc(text_features)
        fused_features = torch.cat((mri_features, text_features), dim=1)
        fused_features = self.relu(self.fusion_layer(fused_features))
        return self.classifier(fused_features)

# ---------------------------
# (1) MRI-Only í•™ìŠµ ë° í…ŒìŠ¤íŠ¸
# ---------------------------
def train_mri_only():
    print("\nðŸš€ Training MRI-Only Model (ResNet-10 + Classifier) ðŸš€\n")
    train_dataset, val_dataset, test_dataset = split_data(matched_data)
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)

    mri_encoder = MedicalNetEncoder(feature_dim=512, use_pretrained=True).to(device)

    # mri_encoder ì¶œë ¥ ì°¨ì›ì„ ìžë™ê³„ì‚°í•˜ì—¬ classifier í¬ê¸° ë§žì¶¤
    sample_input = torch.randn(1, 1, 16, 112, 112).to(device)
    sample_output = mri_encoder(sample_input)
    feature_dim = sample_output.view(sample_output.size(0), -1).shape[1]  # Flatten í›„ í¬ê¸°

    #classifier = nn.Linear(feature_dim, 4).to(device)
    classifier = nn.Sequential(
            nn.Linear(feature_dim, 256),
            nn.ReLU(),
            nn.Linear(256, 64),
            nn.ReLU(),
            nn.Linear(64, 4)
        ).to(device)


    optimizer = torch.optim.Adam(list(mri_encoder.parameters()) + list(classifier.parameters()), lr=0.001)
    criterion = nn.CrossEntropyLoss()

    num_epochs = 5
    for epoch in range(num_epochs):
        mri_encoder.train()
        classifier.train()
        for batch in tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epochs} (MRI-Only)", unit="batch"):
            mri_tensor, _, labels = batch
            mri_tensor, labels = mri_tensor.to(device), labels.to(device)

            mri_features = mri_encoder(mri_tensor)
            mri_features = mri_features.view(mri_features.size(0), -1)
            output = classifier(mri_features)

            optimizer.zero_grad()
            loss = criterion(output, labels)
            loss.backward()
            optimizer.step()

    print("\nâœ… MRI-Only Model Training Complete!\n")
    # í•™ìŠµì´ ëë‚œ ëª¨ë¸ê³¼ test_loaderë¥¼ ë¦¬í„´
    return mri_encoder, classifier, test_loader

def test_mri_only(mri_encoder, classifier, test_loader):
    print("\nðŸ”Ž Testing MRI-Only Model...\n")
    mri_encoder.eval()
    classifier.eval()

    correct = 0
    total = 0
    with torch.no_grad():
        for mri_tensor, _, labels in test_loader:
            mri_tensor, labels = mri_tensor.to(device), labels.to(device)

            # ì¶”ë¡ 
            mri_features = mri_encoder(mri_tensor)
            mri_features = mri_features.view(mri_features.size(0), -1)
            output = classifier(mri_features)

            # ì˜ˆì¸¡ ë° ì •í™•ë„ ê³„ì‚°
            _, preds = torch.max(output, dim=1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)

    accuracy = 100.0 * correct / total if total > 0 else 0
    print(f"âœ… MRI-Only Test Accuracy: {accuracy:.2f}% ({correct}/{total})")


# ---------------------------
# (2) Multimodal í•™ìŠµ ë° í…ŒìŠ¤íŠ¸
# ---------------------------
def train_multimodal():
    print("\nðŸš€ Training Multimodal Model (MRI + CLIP Text) ðŸš€\n")

    train_dataset, val_dataset, test_dataset = split_data(matched_data)
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)

    mri_encoder = MedicalNetEncoder(feature_dim=512, use_pretrained=True).to(device)
    text_encoder = TextEncoder().to(device)
    # multimodal ë¶„ë¥˜ëª¨ë¸
    # mri_encoder ì¶œë ¥ ì±„ë„(6272 ê°€ì •) ìžë™ ê³„ì‚°
    sample_input = torch.randn(1, 1, 16, 112, 112).to(device)
    sample_mri_features = mri_encoder(sample_input)
    mri_feature_dim = sample_mri_features.view(sample_mri_features.size(0), -1).shape[1]

    # text_encoder ì¶œë ¥ ì±„ë„(512) + mri_feature_dim -> fusion
    # ì—¬ê¸°ì„œëŠ” MultimodalClassifier ì‚¬ìš© ì‹œ
    # ë‚´ë¶€ì ìœ¼ë¡œ mri_fc(in_features=6272)ë¡œ ê³„ì‚°.
    # mri_feature_dimì´ 6272ê°€ ì•„ë‹ˆë¼ë©´ í•´ë‹¹ ê°’ìœ¼ë¡œ ìˆ˜ì • í•„ìš”.
    # ì¼ë‹¨ ì•„ëž˜ì²˜ëŸ¼ ì‹¤ì œ ê³„ì‚°ëœ ì°¨ì›ì„ ë°”ë¡œ ì§‘ì–´ë„£ë„ë¡ í•©ë‹ˆë‹¤.
    multimodal_model = MultimodalClassifier(feature_dim=512, num_classes=4).to(device)
    multimodal_model.mri_fc = nn.Linear(mri_feature_dim, 512).to(device)

    optimizer = torch.optim.Adam(
        list(mri_encoder.parameters()) + list(text_encoder.parameters()) + list(multimodal_model.parameters()), 
        lr=0.001
    )
    criterion = nn.CrossEntropyLoss()

    num_epochs = 5
    for epoch in range(num_epochs):
        mri_encoder.train()
        text_encoder.model.train()
        multimodal_model.train()

        for batch in tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epochs} (Multimodal)", unit="batch"):
            mri_tensor, text_inputs, labels = batch
            mri_tensor, labels = mri_tensor.to(device), labels.to(device)

            # í…ìŠ¤íŠ¸ ìž„ë² ë”© ì¶”ì¶œ
            text_inputs_proc = text_encoder.processor(text=text_inputs, return_tensors="pt", padding=True, truncation=True).to(device)
            text_features = text_encoder.model.get_text_features(**text_inputs_proc)

            # MRI ìž„ë² ë”© ì¶”ì¶œ
            mri_features = mri_encoder(mri_tensor)

            # ë©€í‹°ëª¨ë‹¬ ë¶„ë¥˜
            output = multimodal_model(mri_features, text_features)
            loss = criterion(output, labels)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

        print(f"Epoch [{epoch + 1}/{num_epochs}] Completed!")

    print("\nâœ… Multimodal Model Training Complete!\n")
    return mri_encoder, text_encoder, multimodal_model, test_loader

def test_multimodal(mri_encoder, text_encoder, multimodal_model, test_loader):
    print("\nðŸ”Ž Testing Multimodal Model...\n")
    mri_encoder.eval()
    text_encoder.model.eval()
    multimodal_model.eval()

    correct = 0
    total = 0
    with torch.no_grad():
        for mri_tensor, text_inputs, labels in test_loader:
            mri_tensor, labels = mri_tensor.to(device), labels.to(device)

            # í…ìŠ¤íŠ¸ ìž„ë² ë”© ì¶”ì¶œ
            text_inputs_proc = text_encoder.processor(text=text_inputs, return_tensors="pt", padding=True, truncation=True).to(device)
            text_features = text_encoder.model.get_text_features(**text_inputs_proc)

            # MRI ìž„ë² ë”© ì¶”ì¶œ
            mri_features = mri_encoder(mri_tensor)

            # ë©€í‹°ëª¨ë‹¬ ë¶„ë¥˜ ì¶”ë¡ 
            output = multimodal_model(mri_features, text_features)

            # ì˜ˆì¸¡ ë° ì •í™•ë„ ê³„ì‚°
            _, preds = torch.max(output, dim=1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)

    accuracy = 100.0 * correct / total if total > 0 else 0
    print(f"âœ… Multimodal Test Accuracy: {accuracy:.2f}% ({correct}/{total})")


if __name__ == "__main__":
    # 1) MRI-Only í•™ìŠµ í›„ í…ŒìŠ¤íŠ¸
    mri_encoder, classifier, test_loader_mri = train_mri_only()
    test_mri_only(mri_encoder, classifier, test_loader_mri)

    # 2) Multimodal (MRI + CLIP Text) í•™ìŠµ í›„ í…ŒìŠ¤íŠ¸
    mri_encoder_multi, text_encoder, multimodal_model, test_loader_multi = train_multimodal()
    test_multimodal(mri_encoder_multi, text_encoder, multimodal_model, test_loader_multi)
