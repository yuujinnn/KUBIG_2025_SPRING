
# YOLOv8 ì„¤ì¹˜ (Ultralytics)
!pip install ultralytics
!pip install torch torchvision torchaudio

import torch
from ultralytics import YOLO

# GPU í™•ì¸
print("CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€:", torch.cuda.is_available())
print("ì‚¬ìš© ê°€ëŠ¥í•œ GPU ê°œìˆ˜:", torch.cuda.device_count())
print("í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ GPU:", torch.cuda.get_device_name(0) if torch.cuda.is_available() else "N/A")

pip install ultralytics opencv-python matplotlib tqdm

from google.colab import drive
drive.mount('/content/drive')

'''upscaled dataì—ì„œ ì¡°ë¥˜ íƒì§€ í›„ json íŒŒì¼ë¡œ ë°•ìŠ¤, ì™¸ê³½ì„  ìœ„ì¹˜ ì €ì¥'''

# ë°”ìš´ë”© ë°•ìŠ¤ í•œê°œë§Œ í—ˆìš©
import cv2
import os
import glob
import shutil
import numpy as np
import json
import torch
from tqdm import tqdm
from ultralytics import YOLO

# YOLO v8 ëª¨ë¸ ë¡œë“œ
model = YOLO("yolov8x-seg.pt")

# ì…ë ¥ ë° ì¶œë ¥ í´ë” ì„¤ì •
input_folder = "/content/drive/MyDrive/yolo_dataset/images"
output_folder = "/content/drive/MyDrive/yolo_dataset/bounded_images"

if os.path.exists(output_folder):
    shutil.rmtree(output_folder)
os.makedirs(output_folder, exist_ok=True)

# COCO í˜•ì‹ì˜ ì–´ë…¸í…Œì´ì…˜ ì €ì¥ í´ë”
annotations_file = os.path.join(output_folder, "coco_annotations.json")
coco_annotations = {
    "images": [],
    "annotations": [],
    "categories": []
}

# íƒì§€ ì‹¤íŒ¨ ë¡œê·¸ íŒŒì¼ ìƒì„±
log_file = os.path.join(output_folder, "failed_images.txt")
failed_log = open(log_file, "w")

# ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
image_paths = glob.glob(os.path.join(input_folder, "*.png"))
image_paths += glob.glob(os.path.join(input_folder, "*.jpg"))
image_paths += glob.glob(os.path.join(input_folder, "*.jpeg"))

print(f"ì´ {len(image_paths)}ê°œì˜ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.")

# ì´ë¯¸ì§€ ì²˜ë¦¬ ë£¨í”„
annotation_id = 1  # ì–´ë…¸í…Œì´ì…˜ ID
category_id = 1  # ë‹¨ì¼ í´ë˜ìŠ¤(ìƒˆ) ê°€ì •

for img_id, img_path in enumerate(tqdm(image_paths, desc="Processing Images")):
    img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)
    if img is None:
        continue

    results = model(img)

    # íƒì§€ëœ ê°ì²´ê°€ ì—†ìœ¼ë©´ ì›ë³¸ ì €ì¥
    if len(results[0].boxes) == 0:
        shutil.copy(img_path, os.path.join(output_folder, os.path.basename(img_path)))
        failed_log.write(f"{img_path}\n")
        continue

    output_img = img.copy()
    img_height, img_width = img.shape[:2]

    # COCO ìŠ¤íƒ€ì¼ ì´ë¯¸ì§€ ì •ë³´ ì €ì¥
    coco_annotations["images"].append({
        "id": img_id,
        "file_name": os.path.basename(img_path),
        "width": img_width,
        "height": img_height
    })

    # ë°”ìš´ë”© ë°•ìŠ¤ ë° ì„¸ê·¸ë©˜í…Œì´ì…˜ ì •ë³´ ì¶”ì¶œ
    for box, mask in zip(results[0].boxes.xyxy.cpu().numpy(), results[0].masks.data.cpu().numpy()):
        x1, y1, x2, y2 = map(int, box)
        bbox_width, bbox_height = x2 - x1, y2 - y1

        # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸° (ì´ˆë¡ìƒ‰)
        cv2.rectangle(output_img, (x1, y1), (x2, y2), (0, 255, 0), 2)

        # ë§ˆìŠ¤í¬ë¥¼ ì›ë³¸ í¬ê¸°ë¡œ ë³€í™˜ í›„ ì ìš©
        mask_resized = cv2.resize(mask, (img_width, img_height))
        mask_binary = (mask_resized > 0.5).astype(np.uint8) * 255  # Threshold ì ìš©

        # ì»¨íˆ¬ì–´(ê°ì²´ ì™¸ê³½ì„ ) ì°¾ê¸°
        contours, _ = cv2.findContours(mask_binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        # COCO Segmentation ì €ì¥ í˜•ì‹ (í´ë¦¬ê³¤ ì¢Œí‘œ)
        segmentation = []
        for cnt in contours:
            if cv2.contourArea(cnt) > 100:  # ë„ˆë¬´ ì‘ì€ ì»¨íˆ¬ì–´ëŠ” ì œì™¸
                flattened = cnt.flatten().tolist()
                segmentation.append(flattened)

        # COCO ì–´ë…¸í…Œì´ì…˜ ì €ì¥
        coco_annotations["annotations"].append({
            "id": annotation_id,
            "image_id": img_id,
            "category_id": category_id,
            "bbox": [x1, y1, bbox_width, bbox_height],
            "segmentation": segmentation,
            "iscrowd": 0,
            "area": bbox_width * bbox_height
        })
        annotation_id += 1

        # ì»¨íˆ¬ì–´ë¥¼ íŒŒë€ìƒ‰ìœ¼ë¡œ ê·¸ë¦¬ê¸° (ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œê°í™”)
        cv2.drawContours(output_img, contours, -1, (0, 0, 255), 2)  # íŒŒë€ìƒ‰ ì»¨íˆ¬ì–´

    # ìµœì¢… ê²°ê³¼ ì €ì¥
    output_path = os.path.join(output_folder, os.path.basename(img_path))
    cv2.imwrite(output_path, output_img)

# COCO ì–´ë…¸í…Œì´ì…˜ JSON ì €ì¥
with open(annotations_file, "w") as f:
    json.dump(coco_annotations, f, indent=4)

# íƒì§€ ì‹¤íŒ¨í•œ ë¡œê·¸ íŒŒì¼ ë‹«ê¸°
failed_log.close()

print(f"âœ… ëª¨ë“  ì´ë¯¸ì§€ ì²˜ë¦¬ ì™„ë£Œ! ê²°ê³¼ëŠ” {output_folder}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
print(f"ğŸ“ COCO ìŠ¤íƒ€ì¼ ì–´ë…¸í…Œì´ì…˜ì´ {annotations_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


# ë°”ìš´ë”© ë°•ìŠ¤ í•œê°œë§Œ í—ˆìš©
import cv2
import os
import glob
import shutil
import numpy as np
import json
import torch
from tqdm import tqdm
from ultralytics import YOLO

# YOLO v8 ëª¨ë¸ ë¡œë“œ
model = YOLO("yolov8x-seg.pt")

# ì…ë ¥ ë° ì¶œë ¥ í´ë” ì„¤ì •
input_folder = "/content/drive/MyDrive/yolo_dataset/images"
output_folder = "/content/drive/MyDrive/yolo_dataset/bounded_images"
if os.path.exists(output_folder):
    shutil.rmtree(output_folder)
os.makedirs(output_folder, exist_ok=True)

# COCO í˜•ì‹ì˜ ì–´ë…¸í…Œì´ì…˜ ì €ì¥ í´ë”
annotations_file = os.path.join(output_folder, "coco_annotations.json")
coco_annotations = {
    "images": [],
    "annotations": [],
    "categories": [{"id": 1, "name": "bird"}]  # 'ìƒˆ' ì¹´í…Œê³ ë¦¬ ì¶”ê°€
}

# íƒì§€ ì‹¤íŒ¨ ë¡œê·¸ íŒŒì¼ ìƒì„±
log_file = os.path.join(output_folder, "failed_images.txt")
failed_log = open(log_file, "w")

# ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
image_paths = glob.glob(os.path.join(input_folder, "*.png"))
image_paths += glob.glob(os.path.join(input_folder, "*.jpg"))
image_paths += glob.glob(os.path.join(input_folder, "*.jpeg"))

print(f"ì´ {len(image_paths)}ê°œì˜ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.")

# ì´ë¯¸ì§€ ì²˜ë¦¬ ë£¨í”„
annotation_id = 1  # ì–´ë…¸í…Œì´ì…˜ ID
category_id = 1  # ë‹¨ì¼ í´ë˜ìŠ¤(ìƒˆ) ê°€ì •

for img_id, img_path in enumerate(tqdm(image_paths, desc="Processing Images")):
    img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)
    if img is None:
        continue

    results = model(img)

    # íƒì§€ëœ ê°ì²´ê°€ ì—†ìœ¼ë©´ ì›ë³¸ ì €ì¥
    if len(results[0].boxes) == 0:
        shutil.copy(img_path, os.path.join(output_folder, os.path.basename(img_path)))
        failed_log.write(f"{img_path}\n")
        continue

    output_img = img.copy()
    img_height, img_width = img.shape[:2]

    # COCO ìŠ¤íƒ€ì¼ ì´ë¯¸ì§€ ì •ë³´ ì €ì¥
    coco_annotations["images"].append({
        "id": img_id,
        "file_name": os.path.basename(img_path),
        "width": img_width,
        "height": img_height
    })

    # ë°”ìš´ë”© ë°•ìŠ¤ ë° ì‹ ë¢°ë„ ì •ë ¬ (ì‹ ë¢°ë„ê°€ ê°€ì¥ ë†’ì€ í•œ ê°œë§Œ ì„ íƒ)
    detections = list(zip(results[0].boxes.xyxy.cpu().numpy(), results[0].masks.data.cpu().numpy(), results[0].boxes.conf.cpu().numpy()))
    detections.sort(key=lambda x: x[2], reverse=True)  # ì‹ ë¢°ë„(conf) ê¸°ì¤€ ì •ë ¬

    if detections:  # ê°ì§€ëœ ê°ì²´ê°€ ìˆëŠ” ê²½ìš°
        box, mask, conf = detections[0]  # ê°€ì¥ ì‹ ë¢°ë„ ë†’ì€ í•œ ê°œë§Œ ì„ íƒ
        x1, y1, x2, y2 = map(int, box)
        bbox_width, bbox_height = x2 - x1, y2 - y1

        # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸° (ì´ˆë¡ìƒ‰)
        cv2.rectangle(output_img, (x1, y1), (x2, y2), (0, 255, 0), 2)

        # ë§ˆìŠ¤í¬ë¥¼ ì›ë³¸ í¬ê¸°ë¡œ ë³€í™˜ í›„ ì ìš©
        mask_resized = cv2.resize(mask, (img_width, img_height))
        mask_binary = (mask_resized > 0.5).astype(np.uint8) * 255  # Threshold ì ìš©

        # ì»¨íˆ¬ì–´(ê°ì²´ ì™¸ê³½ì„ ) ì°¾ê¸°
        contours, _ = cv2.findContours(mask_binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        # COCO Segmentation ì €ì¥ í˜•ì‹ (í´ë¦¬ê³¤ ì¢Œí‘œ)
        segmentation = []
        for cnt in contours:
            if cv2.contourArea(cnt) > 100:  # ë„ˆë¬´ ì‘ì€ ì»¨íˆ¬ì–´ëŠ” ì œì™¸
                flattened = cnt.flatten().tolist()
                segmentation.append(flattened)

        # COCO ì–´ë…¸í…Œì´ì…˜ ì €ì¥ (ê°€ì¥ ì‹ ë¢°ë„ ë†’ì€ ê°ì²´ë§Œ ì¶”ê°€)
        coco_annotations["annotations"].append({
            "id": annotation_id,
            "image_id": img_id,
            "category_id": category_id,
            "bbox": [x1, y1, bbox_width, bbox_height],
            "segmentation": segmentation,
            "iscrowd": 0,
            "area": bbox_width * bbox_height
        })
        annotation_id += 1

        # ì»¨íˆ¬ì–´ë¥¼ íŒŒë€ìƒ‰ìœ¼ë¡œ ê·¸ë¦¬ê¸° (ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œê°í™”)
        cv2.drawContours(output_img, contours, -1, (0, 0, 255), 2)  # íŒŒë€ìƒ‰ ì»¨íˆ¬ì–´

    # ìµœì¢… ê²°ê³¼ ì €ì¥
    output_path = os.path.join(output_folder, os.path.basename(img_path))
    cv2.imwrite(output_path, output_img)

# COCO ì–´ë…¸í…Œì´ì…˜ JSON ì €ì¥
with open(annotations_file, "w") as f:
    json.dump(coco_annotations, f, indent=4)

# íƒì§€ ì‹¤íŒ¨í•œ ë¡œê·¸ íŒŒì¼ ë‹«ê¸°
failed_log.close()

print(f"âœ… ëª¨ë“  ì´ë¯¸ì§€ ì²˜ë¦¬ ì™„ë£Œ! ê²°ê³¼ëŠ” {output_folder}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
print(f"ğŸ“ COCO ìŠ¤íƒ€ì¼ ì–´ë…¸í…Œì´ì…˜ì´ {annotations_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

'''label ìƒì„±'''

import json
import os

# íŒŒì¼ ê²½ë¡œ ì„¤ì •
annotations_path = "/content/drive/MyDrive/yolo_dataset/coco_annotations.json"
labels_folder = "/content/drive/MyDrive/yolo_dataset/labels_seg"

# ì €ì¥ í´ë” ìƒì„±
os.makedirs(labels_folder, exist_ok=True)

# COCO ì–´ë…¸í…Œì´ì…˜ ë¡œë“œ
with open(annotations_path, "r") as f:
    coco_data = json.load(f)

# ì´ë¯¸ì§€ ì •ë³´ ë”•ì…”ë„ˆë¦¬ ìƒì„±
image_info = {img["id"]: img for img in coco_data["images"]}

# YOLO í˜•ì‹ìœ¼ë¡œ ë³€í™˜
for ann in coco_data["annotations"]:
    image_id = ann["image_id"]

    if image_id not in image_info:
        print(f"âš  ê²½ê³ : image_id {image_id}ê°€ COCO ë°ì´í„°ì— ì—†ìŒ, ìŠ¤í‚µí•©ë‹ˆë‹¤.")
        continue

    file_name = image_info[image_id]["file_name"]
    img_width = image_info[image_id]["width"]
    img_height = image_info[image_id]["height"]

    # YOLO í˜•ì‹ ë°”ìš´ë”© ë°•ìŠ¤ ë³€í™˜
    x1, y1, w, h = ann["bbox"]
    x_center = (x1 + w / 2) / img_width
    y_center = (y1 + h / 2) / img_height
    norm_width = w / img_width
    norm_height = h / img_height

    # YOLO ì„¸ê·¸ë©˜í…Œì´ì…˜ ë³€í™˜ (ì»¨íˆ¬ì–´ í´ë¦¬ê³¤ ì¢Œí‘œ ì •ê·œí™”)
    segmentation = []
    for segment in ann["segmentation"]:
        normalized_segment = [segment[i] / img_width if i % 2 == 0 else segment[i] / img_height for i in range(len(segment))]
        segmentation.extend(normalized_segment)

    # ìµœëŒ€ 16ê°œ ì¢Œí‘œ(x,y) ì œí•œ (YOLOëŠ” ìµœëŒ€ 16ê°œ ì  ì‚¬ìš© ê°€ëŠ¥)
    if len(segmentation) > 32:  # 16ê°œ ìŒ(32ê°œ ê°’) ì´ˆê³¼ ì‹œ ê· ë“±í•œ ê°„ê²©ìœ¼ë¡œ 16ê°œ ìƒ˜í”Œë§
      indices = np.linspace(0, len(segmentation) // 2 - 1, 16, dtype=int)  # 16ê°œ ì¸ë±ìŠ¤ ê· ë“± ìƒ˜í”Œë§
      segmentation = [segmentation[i * 2] for i in indices] + [segmentation[i * 2 + 1] for i in indices]  # x, y ì¢Œí‘œ ë¶„ë¦¬ í›„ ì¬ì¡°í•©

    # YOLO ë¼ë²¨ íŒŒì¼ëª…
    label_file = os.path.join(labels_folder, os.path.splitext(file_name)[0] + ".txt")

    # YOLO Segmentation ë¼ë²¨ íŒŒì¼ ì €ì¥
    with open(label_file, "w") as f:
        category_id = ann["category_id"] - 1  # YOLOëŠ” í´ë˜ìŠ¤ IDë¥¼ 0ë¶€í„° ì‹œì‘
        f.write(f"{category_id} " + " ".join(map(str, segmentation)) + "\n")

print(f"âœ… YOLO ì„¸ê·¸ë©˜í…Œì´ì…˜ í¬ë§· ë³€í™˜ ì™„ë£Œ! ë¼ë²¨ íŒŒì¼ì´ {labels_folder}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

'''ëª¨ë¸ í•™ìŠµ'''

import os
import yaml

# ğŸ“Œ ë°ì´í„° ê²½ë¡œ ì„¤ì •
dataset_path = "/content/drive/MyDrive/yolo_dataset/model_building"
images_path = os.path.join(dataset_path, "images")
labels_path = os.path.join(dataset_path, "labels_seg")  # ì„¸ê·¸ë©˜í…Œì´ì…˜ ë¼ë²¨ ì‚¬ìš©

# ğŸ“Œ data.yaml íŒŒì¼ ìƒì„± (trainê³¼ valì„ ë™ì¼í•˜ê²Œ ì„¤ì •)
data_yaml = {
    "train": images_path,  # ëª¨ë“  ë°ì´í„°ë¥¼ trainìœ¼ë¡œ ì‚¬ìš©
    "val": images_path,    # ë™ì¼í•œ ë°ì´í„°ë¥¼ valë¡œ ì‚¬ìš©
    "nc": 1,               # í´ë˜ìŠ¤ ê°œìˆ˜ (ìƒˆ 1ì¢…)
    "names": ["bird"],     # í´ë˜ìŠ¤ ì´ë¦„
    "task": "segment"      # ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ í•™ìŠµ
}

yaml_path = os.path.join(dataset_path, "data.yaml")
with open(yaml_path, "w") as f:
    yaml.dump(data_yaml, f, default_flow_style=False)

print(f"âœ… data.yaml íŒŒì¼ ìƒì„± ì™„ë£Œ: {yaml_path}")

!yolo task=segment mode=train model=yolov8m-seg.pt data="/content/drive/MyDrive/yolo_dataset/data.yaml" epochs=50 imgsz=512 device=0 workers=16 batch=64