import os
import glob
import json
import pickle
from tqdm import tqdm
from langchain.vectorstores import Chroma
from langchain.embeddings import HuggingFaceEmbeddings

# âœ… ê²½ë¡œ ë° ì„¤ì •
PERSIST_DIR = "/Users/yarlu/Desktop/KUBIG/NLP_PJ"
COLLECTION_NAME = "my_collection"
PICKLE_PATH = "collection_backup_final.pkl"

# âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
embedding_model_name = "snunlp/KR-SBERT-V40K-klueNLI-augSTS"
print("ğŸš€ ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘...")
embedding_fn = HuggingFaceEmbeddings(
    model_name=embedding_model_name,
    encode_kwargs={"normalize_embeddings": True},
)
print("âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")

# âœ… ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ë˜ëŠ” ìƒˆë¡œ ìƒì„±
try:
    vectorstore = Chroma(
        persist_directory=PERSIST_DIR,
        embedding_function=embedding_fn
    )
    print("âœ… ê¸°ì¡´ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì™„ë£Œ!")
except Exception as e:
    print(f"âš ï¸ ê¸°ì¡´ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì‹¤íŒ¨: {e}")
    vectorstore = Chroma.from_documents(
        documents=[],  # ë¹ˆ ë¬¸ì„œë¡œ ìƒì„±
        embedding=embedding_fn,
        persist_directory=PERSIST_DIR
    )
    print("ğŸ†• ìƒˆë¡œìš´ ë²¡í„°ìŠ¤í† ì–´ ìƒì„±!")

# âœ… ì„ë² ë”© ìƒì„± ë° ë²¡í„°ìŠ¤í† ì–´ ì¶”ê°€ í•¨ìˆ˜
def build_or_load_embeddings(json_dir="2.ë‹µë³€"):
    """DBì— ì„ë² ë”©ì´ ì—†ìœ¼ë©´ ìƒì„±í•˜ê³ , ìˆìœ¼ë©´ ìŠ¤í‚µí•˜ë©° ì§„í–‰ ìƒí™©ì„ tqdmìœ¼ë¡œ í‘œì‹œ"""
    metadatas = vectorstore.get(include=["metadatas"])["metadatas"]
    existing_ids = {md["fileName"] for md in metadatas} if metadatas else set()

    json_paths = glob.glob(f"{json_dir}/**/*.json", recursive=True)
    print(f"ğŸ” ì´ {len(json_paths)}ê°œì˜ JSON íŒŒì¼ ë°œê²¬!")

    added_count = 0

    for path in tqdm(json_paths, desc="ì„ë² ë”© ì²˜ë¦¬ ì§„í–‰ ì¤‘", unit="íŒŒì¼"):
        file_id = os.path.basename(path)
        if file_id in existing_ids:
            continue  # ì´ë¯¸ ì²˜ë¦¬ëœ íŒŒì¼ì€ ìŠ¤í‚µ

        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)

        disease_kor_text = data.get("disease_name", {}).get("kor", "")
        department_text = ", ".join(data.get("department", [])) if isinstance(data.get("department", []), list) else data.get("department", "")
        intention_text = data.get("intention", "")
        answer_text = " ".join(data.get("answer", {}).values()) if isinstance(data.get("answer", {}), dict) else str(data.get("answer", ""))

        # âœ… ì„ë² ë”© ìƒì„±
        emb_disease = embedding_fn.embed_query(disease_kor_text)
        emb_department = embedding_fn.embed_query(department_text)
        emb_intention = embedding_fn.embed_query(intention_text)
        emb_answer = embedding_fn.embed_query(answer_text)

        metadata = {
            "fileName": file_id,
            "disease_name_kor_vec": json.dumps(emb_disease),
            "department_vec": json.dumps(emb_department),
            "intention_vec": json.dumps(emb_intention),
            "answer_vec": json.dumps(emb_answer),
            "disease_name_kor_text": disease_kor_text,
            "department_text": department_text,
            "intention_text": intention_text,
            "answer_text": answer_text
        }

        # âœ… ë²¡í„°ìŠ¤í† ì–´ì— ì¶”ê°€
        vectorstore.add_texts(
            texts=[answer_text],
            metadatas=[metadata],
            ids=[file_id]
        )
        added_count += 1

    # âœ… í¼ì‹œìŠ¤í„´ìŠ¤ ì €ì¥
    vectorstore.persist()
    print(f"ğŸ’¾ ë²¡í„°ìŠ¤í† ì–´ê°€ '{PERSIST_DIR}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    if added_count:
        print(f"âœ… {added_count}ê°œì˜ ìƒˆ ì„ë² ë”© ì¶”ê°€ ì™„ë£Œ.")
    else:
        print("âœ… ê¸°ì¡´ ì„ë² ë”© ì‚¬ìš© (ìƒˆë¡œ ì¶”ê°€ëœ íŒŒì¼ ì—†ìŒ).")

    # âœ… Pickleë¡œ ë°±ì—… ì €ì¥
    data = vectorstore.get(include=["metadatas", "documents"])
    with open(PICKLE_PATH, "wb") as f:
        pickle.dump(data, f)
    print(f"âœ… Pickle íŒŒì¼ë¡œ '{PICKLE_PATH}'ì— ë°±ì—… ì €ì¥ ì™„ë£Œ!")

# âœ… ì„ë² ë”© ë¹Œë“œ ì‹¤í–‰
build_or_load_embeddings()