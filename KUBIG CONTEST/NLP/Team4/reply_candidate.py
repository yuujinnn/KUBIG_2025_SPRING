import os
import json
import time
from langchain.vectorstores import Chroma
from langchain.embeddings import HuggingFaceEmbeddings
import numpy as np

# âœ… ê²½ë¡œ ë° ì„¤ì •
PERSIST_DIR = "/Users/yarlu/Desktop/KUBIG/NLP_PJ"
embedding_model_name = "snunlp/KR-SBERT-V40K-klueNLI-augSTS"

# âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
print("ğŸš€ ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘...")
embedding_fn = HuggingFaceEmbeddings(
    model_name=embedding_model_name,
    encode_kwargs={"normalize_embeddings": True},
)
print("âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")

# âœ… í¼ì‹œìŠ¤í„´ìŠ¤ íŒŒì¼(chroma.sqlite3)ë¡œë¶€í„° ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ
vectorstore = Chroma(
    persist_directory=PERSIST_DIR,
    embedding_function=embedding_fn
)
print("âœ… í¼ì‹œìŠ¤í„´ìŠ¤ íŒŒì¼ì—ì„œ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì™„ë£Œ!")


# âœ… ì½”ì‚¬ì¸ ìœ ì‚¬ë„ í•¨ìˆ˜
def cosine_sim(a, b):
    a, b = np.array(a), np.array(b)
    return float(np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b)))


def custom_search(user_disease_name_kor, user_department, user_intention, user_question, top_k=3):
    start_time = time.time()
    # âœ… ì‚¬ìš©ì ì…ë ¥ ì„ë² ë”© ìƒì„±
    emb_user_disease = embedding_fn.embed_query(user_disease_name_kor)
    emb_user_department = embedding_fn.embed_query(user_department)
    emb_user_intention = embedding_fn.embed_query(user_intention)
    emb_user_question = embedding_fn.embed_query(
        ", ".join(user_question[:4]) if isinstance(user_question, list) else user_question
    )

    # âœ… ì»¬ë ‰ì…˜ ë©”íƒ€ë°ì´í„° ë° ë¬¸ì„œ ë¶ˆëŸ¬ì˜¤ê¸°
    results = vectorstore.get(include=["metadatas", "documents"])
    metadatas = results["metadatas"]
    documents = results["documents"]

    scored_docs = []

    # âœ… ê° ë¬¸ì„œì™€ ì‚¬ìš©ì ì…ë ¥ ê°„ì˜ í‰ê·  ìœ ì‚¬ë„ ê³„ì‚°
    for md, doc in zip(metadatas, documents):
        doc_id = md.get("fileName", "unknown")

        # ë©”íƒ€ë°ì´í„°ì—ì„œ ì„ë² ë”© ë¶ˆëŸ¬ì˜¤ê¸°
        emb_doc_disease = json.loads(md["disease_name_kor_vec"])
        emb_doc_dept = json.loads(md["department_vec"])
        emb_doc_intent = json.loads(md["intention_vec"])
        emb_doc_answer = json.loads(md["answer_vec"])

        # í‰ê·  ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        avg_sim = (
            cosine_sim(emb_user_disease, emb_doc_disease) +
            cosine_sim(emb_user_department, emb_doc_dept) +
            cosine_sim(emb_user_intention, emb_doc_intent) +
            cosine_sim(emb_user_question, emb_doc_answer)
        ) / 4.0

        scored_docs.append({
            "id": doc_id,
            "answer_text": md["answer_text"],
            "similarity": avg_sim
        })

    # âœ… ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬ ë° ìƒìœ„ top_k ë°˜í™˜
    scored_docs.sort(key=lambda x: x["similarity"], reverse=True)

    end_time = time.time()
    elapsed_time = end_time - start_time

    print("\n=== ê²€ìƒ‰ ê²°ê³¼ ===")
    for rank, doc in enumerate(scored_docs[:top_k], start=1):
        print(f"[{rank}ìœ„] ID: {doc['id']} / ìœ ì‚¬ë„: {doc['similarity']:.4f}")
        print(f"     â†’ answer_text: {doc['answer_text']}...\n")
    print(f"ì†Œìš”ì‹œê°„:{elapsed_time}")
    return scored_docs[:top_k]

def custom_search_only_query(user_disease_name_kor, user_department, user_intention, user_question, top_k=3):
    start_time = time.time()
    emb_user_question = embedding_fn.embed_query(", ".join(user_question[:4]) if isinstance(user_question, list) else user_question)

    results = vectorstore.get(include=["metadatas", "documents"])
    metadatas = results["metadatas"]
    documents = results["documents"]

    scored_docs = []
    for md in metadatas:
        doc_id = md.get("fileName", "unknown")
        emb_doc_answer = json.loads(md["answer_vec"])

        sim_quest = cosine_sim(emb_user_question, emb_doc_answer)

        scored_docs.append({
            "id": doc_id,
            "answer_text": md["answer_text"],
            "similarity": sim_quest
        })

    scored_docs.sort(key=lambda x: x["similarity"], reverse=True)

    end_time = time.time()
    elapsed_time = end_time - start_time

    print("=== ê²€ìƒ‰ ê²°ê³¼ ===")
    for rank, doc in enumerate(scored_docs[:top_k], start=1):
        print(f"[{rank}ìœ„] ID: {doc['id']} / ìœ ì‚¬ë„: {doc['similarity']:.4f}")
        print(f"     â†’ answer_text: {doc['answer_text']}...")
        print()
    print(f"ì†Œìš”ì‹œê°„:{elapsed_time}")
    
    return scored_docs[:top_k]

def custom_search_all(user_disease_name_kor, user_department, user_intention, user_question, user_keyword, top_k=3):
    start_time = time.time()
    emb_user_disease = embedding_fn.embed_query(user_disease_name_kor)
    emb_user_department = embedding_fn.embed_query(user_department)
    emb_user_intention = embedding_fn.embed_query(user_intention)
    emb_user_question = embedding_fn.embed_query(", ".join(user_question[:4]) if isinstance(user_question, list) else user_question)
    emb_user_keyword = embedding_fn.embed_query(", ".join(user_keyword[:4]) if isinstance(user_keyword, list) else user_keyword)

    results = vectorstore.get(include=["metadatas", "documents"])
    metadatas = results["metadatas"]
    documents = results["documents"]

    scored_docs = []

    for md in metadatas:
        doc_id = md.get("fileName", "unknown")

        emb_doc_disease = json.loads(md["disease_name_kor_vec"])
        emb_doc_dept = json.loads(md["department_vec"])
        emb_doc_intent = json.loads(md["intention_vec"])
        emb_doc_answer = json.loads(md["answer_vec"])

        avg_sim = (cosine_sim(emb_user_disease, emb_doc_disease) +
                   cosine_sim(emb_user_department, emb_doc_dept) +
                   cosine_sim(emb_user_intention, emb_doc_intent) +
                   cosine_sim(emb_user_question, emb_doc_answer) +
                   cosine_sim(emb_user_keyword, emb_doc_answer)
                   ) / 5.0

        scored_docs.append({
            "id": doc_id,
            "answer_text": md["answer_text"],
            "similarity": avg_sim
        })

    scored_docs.sort(key=lambda x: x["similarity"], reverse=True)

    end_time = time.time()
    elapsed_time = end_time - start_time

    print("\n=== ê²€ìƒ‰ ê²°ê³¼ ===")
    for rank, doc in enumerate(scored_docs[:top_k], start=1):
        print(f"[{rank}ìœ„] ID: {doc['id']} / ìœ ì‚¬ë„: {doc['similarity']:.4f}")
        print(f"     â†’ answer_text: {doc['answer_text']}...\n")
    print(f"ì†Œìš”ì‹œê°„:{elapsed_time}")

    return scored_docs[:top_k]